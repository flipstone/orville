-- Hoogle documentation, generated by Haddock
-- See Hoogle, http://www.haskell.org/hoogle/


-- | ORM
--   
--   ORM library for PostgreSQL
@package orville-postgresql-legacy
@version 0.9.0.1


module Database.Orville.PostgreSQL.Connection

-- | <a>createConnectionPool</a> allocates a pool of connections to a
--   PosgreSQL server. The returned pool can be used as the endpoint to
--   <a>newOrvilleEnv</a> to construct.
createConnectionPool :: Int -> NominalDiffTime -> Int -> String -> IO (Pool Connection)
data Pool a
data Connection


module Database.Orville.PostgreSQL.Expr
data RawExpr
rawSql :: String -> RawExpr
class GenerateSql expr
generateSql :: GenerateSql expr => expr -> RawExpr
data Expr a
rawSqlExpr :: String -> Expr a
expr :: a -> Expr a
type NameExpr = Expr NameForm
data NameForm
unescapedName :: NameForm -> String
type SelectExpr = Expr SelectForm
data SelectForm
SelectForm :: NameForm -> Maybe NameForm -> SelectForm
[selectFormColumn] :: SelectForm -> NameForm
[selectFormAlias] :: SelectForm -> Maybe NameForm
selectColumn :: NameForm -> SelectForm
qualified :: QualifySql form => form -> String -> form
aliased :: SelectForm -> NameForm -> SelectForm

module Database.Orville.PostgreSQL.Plan.Explanation
data Explanation
noExplanation :: Explanation
explainStep :: String -> Explanation
explanationSteps :: Explanation -> [String]
instance GHC.Base.Semigroup Database.Orville.PostgreSQL.Plan.Explanation.Explanation
instance GHC.Base.Monoid Database.Orville.PostgreSQL.Plan.Explanation.Explanation

module Database.Orville.PostgreSQL.Plan.Many

-- | A 'Many k a' represents a group of values keyed by list of parameters
--   and is used to return the results of executing an Orville Plan with a
--   list of input parameters. If you need to find the result of the query
--   associated with a particular input parameter, you can use
--   <a>lookup</a> to find it. If you don't care about the association with
--   particular inputs, you can simply use <a>elems</a> to get a list of
--   all the results.
data Many k a

-- | <a>NotAKey</a> is returned from various <a>Many</a> related functions
--   when presented with an input parameter that was not one of the
--   original inputs that the <a>Many</a> was constructed with.
data NotAKey
NotAKey :: NotAKey

-- | <a>fromKeys</a> constructs a <a>Many</a> value from a list of keys and
--   a function that maps them to their values. The order and duplication
--   of keys in the list will be preserved by the <a>Many</a> type in the
--   relevant functions. The mapping function provided should be a total
--   function -- i.e. it should not produce a runtime error. If it is not
--   possible to map every <tt>k</tt> (even those not in the input list
--   provided to <a>fromKeys</a>), the values should be wrapped in an
--   appropriate type such as <a>Maybe</a> so that an empty or default
--   value can be returned.
fromKeys :: [k] -> (k -> Either NotAKey a) -> Many k a

-- | <a>lookup</a> returns the value for the given parameter. If the given
--   <tt>k</tt> is not one of the original input values that the
--   <a>Many</a> was constructed with, the mapping function given at the
--   contructor will determine what value to return. Often this will be
--   whatever a reasonable empty or default value for the type <tt>a</tt>
--   is.
lookup :: k -> Many k a -> Either NotAKey a

-- | <a>keys</a> fetches the list of keys from a <a>Many</a>. Note that is
--   a list and not a set. <a>Many</a> preserves the order and duplication
--   of any key values that were in the key list at the time of
--   construction.
keys :: Many k a -> [k]

-- | <a>elems</a> returns all the values that correspond the keys of the
--   <a>Many</a>. The values will be returned in the same order that the
--   keys were present at the time of creation, though if you truly care
--   about this it's probably better to use <a>lookup</a> to make that
--   correspondence explicit.
elems :: Many k a -> [a]

-- | <a>map</a> calls a function on all the values found in a <a>Many</a>
--   collection.
map :: (a -> b) -> Many k a -> Many k b

-- | <a>toMap</a> converts the <a>Many</a> into a <tt>Map</tt> value. If
--   all you wanted to do was find the value for a specific key, you should
--   probably use <a>lookup</a> instead.
toMap :: Ord k => Many k a -> Map k a

-- | <a>apply</a> allows you to apply many functions to many values. The
--   function associated with each parameter is applied to the value
--   associated with the same paremeter.
--   
--   (If you're looking for <a>pure</a> or an <a>Applicative</a> instance
--   for <a>Many</a>, this is as good as it gets. <a>Many</a> cannot be an
--   <a>Applicative</a> because there is no correct implementation of
--   <a>pure</a> that we can reasonably provide).
apply :: Many param (a -> b) -> Many param a -> Many param b

-- | <a>compose</a> uses the values of a <a>Many</a> value as keys to a
--   second <a>Many</a> to create a <a>Many</a> mapping from the original
--   keys to the final values.
compose :: Many b c -> Many a b -> Many a c
instance GHC.Base.Functor (Database.Orville.PostgreSQL.Plan.Many.Many k)


module Database.Orville.PostgreSQL.Select
data Select row
selectQuery :: FromSql row -> FromClause -> SelectOptions -> Select row
selectQueryTable :: TableDefinition readEntity writeEntity key -> SelectOptions -> Select readEntity
selectQueryRows :: [SelectExpr] -> FromClause -> SelectOptions -> Select [(String, SqlValue)]
selectQueryRaw :: FromSql row -> String -> [SqlValue] -> Select row
selectQueryRawRows :: String -> [SqlValue] -> Select [(String, SqlValue)]
selectQueryColumns :: [SelectExpr] -> FromSql row -> FromClause -> SelectOptions -> Select row
selectField :: FieldDefinition nulability a -> SelectForm
data FromClause
fromClauseRaw :: String -> FromClause
fromClauseTableName :: String -> FromClause
fromClauseTable :: TableDefinition readEntity writeEntity key -> FromClause
runSelect :: MonadOrville conn m => Select row -> m [row]


module Database.Orville.PostgreSQL.Raw
selectSql :: MonadOrville conn m => String -> [SqlValue] -> FromSql result -> m [result]
selectSqlRows :: MonadOrville conn m => String -> [SqlValue] -> m ResultSet
decodeSqlRows :: MonadOrville conn m => FromSql result -> ResultSet -> m [result]
type ResultSet = [[(String, SqlValue)]]
updateSql :: MonadOrville conn m => String -> [SqlValue] -> m Integer
withConnection :: MonadOrville conn m => (conn -> m a) -> m a

-- | Migration Guide: <tt>withTransaction</tt> retains the same name.
withTransaction :: MonadOrville conn m => m a -> m a

-- | Migration Guide: <tt>withCachedConnection</tt> has been renamed to
--   <tt>withConnection_</tt>
--   
--   Runs an action with a cached connection. Without using this, or
--   wrapping calls in a transaction using <a>withTransaction</a>,
--   successive calls to functions like <tt>insertRecord</tt> and
--   <tt>updateRecord</tt> are *not* guaranteed to occur on the same
--   connection.
withCachedConnection :: MonadOrville conn m => m a -> m a


module Database.Orville.PostgreSQL.Conduit

-- | <a>selectConduit</a> provides a way to stream the results of a
--   <a>Select</a> query from the database one by one using the conduit
--   library. You can <a>fuse</a> the conduit built by this function with
--   your own conduit pipeline to handle rows individually in whatever
--   fashion you need (e.g. turning them into rows of CSV). This is useful
--   if you want to be able to process many rows one by one. You can
--   aggregate the results however you require as part of the conduit
--   processing and then use <a>runConduit</a> (or <a>runConduitRes</a>)
--   from the conduit library to execute the processing pipeline.
--   Alternatively, your web server (<tt>wai</tt>, <tt>servant</tt>, etc)
--   may provide support for converting a conduit into a streaming HTTP
--   response.
--   
--   Beware: this function must load all the results into memory before
--   streaming can begin. For why, see
--   <a>https://www.postgresql.org/docs/9.2/libpq-single-row-mode.html</a>.
--   If memory use is a concern, try <a>streamPages</a> instead.
selectConduit :: (Monad m, MonadOrville conn m, MonadCatch m, MonadResource m) => Select row -> ConduitT () row m ()

-- | Build a conduit source that is fed by querying one page worth of
--   results at a time. When the last row of the last page is consumed, the
--   stream ends.
streamPages :: (MonadOrville conn m, Bounded orderField, Enum orderField) => TableDefinition readEnt write key -> FieldDefinition NotNull orderField -> (readEnt -> orderField) -> Maybe WhereCondition -> Word -> ConduitT () readEnt m ()


-- | Migration Guide: Although not all exports are identical, most of the
--   items in this module can now be imported from
--   <tt>Orville.PostgreSQL</tt>.
--   
--   Please note that the new LibPQ-based version of orville represents a
--   complete re-write of Orville from the ground up. As such many of the
--   APIs have been re-thought with the goal of providing stability and
--   better experience long term.
--   
--   Major changes:
--   
--   <ul>
--   <li>The library no longer allows the connection type to vary. It is
--   intended only to be used with PostgreSQL. Thus <a>MonadOrville</a> and
--   other types that used to have a <tt>conn</tt> type parameter no longer
--   have that parameter.</li>
--   <li><a>OrvilleT</a> has been removed in favor of simply using
--   <tt>ReaderT</tt>. For trivial cases (i.e. <tt>ReaderT</tt> over
--   <tt>IO</tt>) a pre-packaged <tt>Orville</tt> monad is provided.</li>
--   <li>In <a>TableDefinition</a>, the order of the type parameters has
--   changed from <tt>TableDefinition readEnity writeEntity key</tt> to
--   <tt>TableDefinition key writeEntity readEntity</tt>. This make it more
--   consistent with the order of these arguments in other types.
--   <a>TableParams</a> has been removed in favor of building a basic table
--   definition with the require parameters first and adding or setting
--   other optional items after initial construction.</li>
--   <li><a>RelationalMap</a> has been replaced by <tt>SqlMarshaller</tt>.
--   Many functions have been renamed, but most functions have a direct or
--   nearly direct translation from the old ones. See the docs on the
--   individual functions such as <a>attrField</a> to see what has
--   changed.</li>
--   <li>The auto-migration system is significantly improved. Standard
--   indexes no longer need to be given explicit names. Indexes and
--   constraints are now attached to <a>TableDefinition</a> rather than
--   being their own schema items. Indexes and constraints are no longer
--   dropped explicitly -- they are dropped automatically by Orville when
--   they have been removed from the table definiton.</li>
--   <li>A number of places that previously accepted <tt>[]</tt> now
--   require <tt>NonEmpty</tt> instead. This is done in places where an
--   empty list would not be valid SQL. For examples of this change see
--   <a>insertRecordMany</a> and <a>updateFields</a>.</li>
--   <li><a>whereAnd</a> and <a>whereOr</a> (which took lists) have been
--   replaced with binary boolean logic functions <tt>andExpr</tt> and
--   <tt>orExpr</tt>. These functions also have operator aliases
--   (<tt>(.&amp;&amp;)</tt>, <tt>(.||)</tt>).</li>
--   </ul>
--   
--   The following items exported from this module have migration guide
--   notes available in their documentation:
--   
--   <ul>
--   <li><a>TableDefinition</a></li>
--   <li><a>mkTableDefinition</a></li>
--   <li><a>TableParams</a></li>
--   <li><a>RelationalMap</a></li>
--   <li><a>fields</a></li>
--   <li><a>mapAttr</a></li>
--   <li><a>mapField</a></li>
--   <li><a>attrField</a></li>
--   <li><a>maybeMapper</a></li>
--   <li><a>prefixMap</a></li>
--   <li><a>partialMap</a></li>
--   <li><a>readOnlyMap</a></li>
--   <li><a>readOnlyField</a></li>
--   <li><a>OrvilleEnv</a></li>
--   <li><a>newOrvilleEnv</a></li>
--   <li><a>setStartTransactionSQL</a></li>
--   <li><a>aroundRunningQuery</a></li>
--   <li><a>addTransactionCallBack</a></li>
--   <li><a>OrvilleT</a></li>
--   <li><a>HasOrvilleContext</a></li>
--   <li><a>MonadOrville</a></li>
--   <li><a>runOrville</a></li>
--   <li><a>mapOrvilleT</a></li>
--   <li><a>MonadOrvilleControl</a></li>
--   <li><a>defaultLiftWithConnection</a></li>
--   <li><a>defaultLiftFinally</a></li>
--   <li><a>withCachedConnection</a></li>
--   <li><a>withTransaction</a></li>
--   <li><a>ColumnFlag</a></li>
--   <li><a>FieldDefinition</a></li>
--   <li><a>isFieldNullable</a></li>
--   <li><a>fieldOfType</a></li>
--   <li><a>textField</a></li>
--   <li><a>fixedTextField</a></li>
--   <li><a>unboundedTextField</a></li>
--   <li><a>dayField</a></li>
--   <li><a>utcTimeField</a></li>
--   <li><a>int32Field</a></li>
--   <li><a>int64Field</a></li>
--   <li><a>doubleField</a></li>
--   <li><a>boolField</a></li>
--   <li><a>automaticIdField</a></li>
--   <li><a>searchVectorField</a></li>
--   <li><a>nullableField</a></li>
--   <li><a>foreignKeyField</a></li>
--   <li><a>withFlag</a></li>
--   <li><a>withName</a></li>
--   <li><a>withConversion</a></li>
--   <li><a>fieldFromSql</a></li>
--   <li><a>fieldToSqlValue</a></li>
--   <li><a>SomeField</a></li>
--   <li><a>withPrefix</a></li>
--   <li><a>fieldFlags</a></li>
--   <li><a>uniqueIndex</a></li>
--   <li><a>simpleIndex</a></li>
--   <li><a>uniqueConstraint</a></li>
--   <li><a>dropConstraint</a></li>
--   <li><a>SchemaItem</a></li>
--   <li><a>SchemaDefinition</a></li>
--   <li><a>Record</a></li>
--   <li><a>WhereCondition</a></li>
--   <li><a>whereAnd</a></li>
--   <li><a>whereOr</a></li>
--   <li><a>whereIn</a></li>
--   <li><a>whereLike</a></li>
--   <li><a>whereLikeInsensitive</a></li>
--   <li><a>whereNotIn</a></li>
--   <li><a>whereQualified</a></li>
--   <li><a>whereRaw</a></li>
--   <li><a>whereToSql</a></li>
--   <li><a>isNull</a></li>
--   <li><a>isNotNull</a></li>
--   <li><a>migrateSchema</a></li>
--   <li><a>generateMigrationPlan</a></li>
--   <li><a>MigrationPlan</a></li>
--   <li><a>MigrationItem</a></li>
--   <li><a>migrationPlanItems</a></li>
--   <li><a>selectAll</a></li>
--   <li><a>selectFirst</a></li>
--   <li><a>deleteRecord</a></li>
--   <li><a>deleteWhere</a></li>
--   <li><a>findRecord</a></li>
--   <li><a>findRecords</a></li>
--   <li><a>findRecordsBy</a></li>
--   <li><a>insertRecord</a></li>
--   <li><a>insertRecordMany</a></li>
--   <li><a>insertRecordManyReturning</a></li>
--   <li><a>updateFields</a></li>
--   <li><a>updateRecord</a></li>
--   <li><a>createIndexesConcurrently</a></li>
--   <li><a>dropIndexesConcurrently</a></li>
--   </ul>
module Database.Orville.PostgreSQL.Core

-- | Migration Guide: <a>TableDefinition</a> can now be imported from
--   <a>PostgreSQL</a>. The order of the type parameters has changed from
--   <tt>TableDefinition readEnity writeEntity key</tt> to
--   <tt>TableDefinition key writeEntity readEntity</tt>. In the new
--   Orville tables without primary keys are supported, so the <tt>key</tt>
--   parameter must now be instantiated as either <tt>HasKey keyType</tt>
--   or <tt>NoKey</tt>.
--   
--   A <a>TableDefinition</a> is the center of the Orville universe. A
--   <a>TableDefinition</a> defines the structure of a table in the
--   database and associates it with a Haskell datatype, usually a Haskell
--   record type. The <a>TableDefinition</a> must specify how the Haskell
--   type is converted to and from the database schema, as as well as
--   provide same basic utility functions required by Orville for
--   interacting with the Haskell datatype.
--   
--   Usually you will use <tt>TableParams</tt> to construct a
--   <a>TableDefinition</a> in a more concise way. This type is provided as
--   an escape hatch for any situations where <tt>TableParams</tt> is too
--   restrictive for the sql mapping required by a type.
data TableDefinition readEntity writeEntity key
TableDefinition :: String -> [SomeField] -> [String] -> PrimaryKey key -> FromSql readEntity -> ToSql writeEntity () -> (readEntity -> key) -> TableComments () -> TableDefinition readEntity writeEntity key

-- | The name of the table in the database.
[tableName] :: TableDefinition readEntity writeEntity key -> String

-- | A list of field definitions defining the table structure
[tableFields] :: TableDefinition readEntity writeEntity key -> [SomeField]

-- | A list of any columns that may be deleted from the table by Orville.
--   (Orville will never delete a column without being told it is safe)
[tableSafeToDelete] :: TableDefinition readEntity writeEntity key -> [String]

-- | The statically typed field definition that is the primary key.
--   Currently this field must still by listed in <a>tableFields</a>
[tablePrimaryKey] :: TableDefinition readEntity writeEntity key -> PrimaryKey key

-- | A definition of how to convert the haskell type from a sql row
[tableFromSql] :: TableDefinition readEntity writeEntity key -> FromSql readEntity

-- | A function to set the key on the entity
[tableToSql] :: TableDefinition readEntity writeEntity key -> ToSql writeEntity ()

-- | A function to get the key on the entity
[tableGetKey] :: TableDefinition readEntity writeEntity key -> readEntity -> key

-- | Any comments that might be interesting for developers to see. These
--   comments will get printed in the log if there is an erro while
--   attempting to migrate the table.
[tableComments] :: TableDefinition readEntity writeEntity key -> TableComments ()
data PrimaryKey key

-- | <a>primaryKeyIn</a> builds a <a>WhereCondition</a> that will match all
--   rows where the primary key is equal to one of the given values. For
--   single-field primary keys this is equivalent to <a>whereIn</a>, but
--   <a>primaryKeyIn</a> also handles composite primary keys.
primaryKeyIn :: PrimaryKey key -> [key] -> WhereCondition

-- | <a>primaryKeyEquals</a> builds a <a>WhereCondition</a> that will match
--   the row where the primary key is equal to the given value. For
--   single-field primary keys this is equivalent to <a>.==</a>, but
--   'primaryKeyEquals also handles composite primary keys.
primaryKeyEquals :: PrimaryKey key -> key -> WhereCondition

-- | <a>primaryKeyDescription</a> builds a user-readable representation of
--   the primary key for use in error messages and such. It is a
--   comma-delimited list of the names of the fields that make up the
--   primary key.
primaryKeyDescription :: PrimaryKey key -> String

-- | <a>primaryKeyToSql</a> converts a Haskell value for a primary key into
--   the (possibly multiple) sql values that represent the primary key in
--   the database.
primaryKeyToSql :: PrimaryKey key -> key -> [SqlValue]

-- | <a>primaryKey</a> constructs a single-field primary key from the
--   <a>FieldDefinition</a> that corresponds to the primary key's column.
--   This is generally used while building a <tt>TableDefinition</tt>.
primaryKey :: FieldDefinition NotNull key -> PrimaryKey key

-- | <a>compositePrimaryKey</a> constructs a multi-field primary key from
--   the given parts, each of which corresponds to one field in the primary
--   key. You should use this while building a <tt>TableDefinition</tt> for
--   a table that you want to have a multi-column primary key. See
--   <a>primaryKeyPart</a> for how to build the parts to be passed as
--   parameters. Note: there is no special significance to the first
--   argument other than requiring that there is at least one field in the
--   primary key.
compositePrimaryKey :: PrimaryKeyPart key -> [PrimaryKeyPart key] -> PrimaryKey key

-- | <a>primaryKeyPart</a> builds on section of a composite primary key
--   based on the field definition that corresponds to that column of the
--   primary key. The function given is used to decompose the Haskell value
--   for the composite key into the individual parts so they can be
--   converted to sql for things like building <a>WhereCondition</a>
primaryKeyPart :: (key -> part) -> FieldDefinition NotNull part -> PrimaryKeyPart key

-- | Migration Guide: This function has in the new orville to take the
--   table name, primary key definition and a <tt>SqlMarshaller</tt>
--   (formerly <tt>RelationalMap</tt>). Other options such as constraints,
--   indexes, and columns to drop can be added to the
--   <tt>TableDefinition</tt> after the initial instantiation. The
--   <tt>TableParams</tt> type has been dropped for the new orville.
--   
--   <a>mkTableDefinition</a> converts a <a>TableParams</a> to
--   <a>TableDefinition</a>. Usually this is used directly on a record
--   literal of the <a>TableParams</a>. For example:
--   
--   <pre>
--   data Foo key = Foo key { fooId :: Record }
--   myTable :: TableDefinition Foo
--   myTable = mkTableDefinition $
--     TableParams
--       { tblName = "foo"
--       , tblMapper = User <a>$</a> attrField fooId idField
--       , tableSafeToDelete = []
--       , tblSetKey = key foo -&gt; foo { fooId = key }
--       , tblGetKey = fooId
--       , tblComments = []
--       }
--   </pre>
mkTableDefinition :: TableParams readEntity writeEntity key -> TableDefinition readEntity writeEntity key

-- | SqlType defines the mapping of a Haskell type (<tt>a</tt>) to a SQL
--   column type in the database. This includes both how to convert the
--   type to and from the raw values read from the database as well as the
--   schema information required to create and migrate columns using the
--   type.
data SqlType a
SqlType :: String -> Maybe String -> SqlTypeId -> Maybe Int -> (a -> SqlValue) -> (SqlValue -> Either RowDataErrorReason a) -> SqlType a

-- | The raw SQL DDL to use when creating/migrating columns of this type
--   (not including any NULL or NOT NULL declarations)
[sqlTypeDDL] :: SqlType a -> String

-- | The raw SQL DDL to use when creating/migrating columns with foreign
--   keys to this type. This is used foreignRefType to build a new SqlType
--   when making foreign key fields
[sqlTypeReferenceDDL] :: SqlType a -> Maybe String

-- | <a>sqlTypeId</a> will be compared to the <tt>colType</tt> field found
--   in the <a>SqlColDesc</a> return by <tt>describeTable</tt> when
--   determining whether a column type change is required when migrating
--   the database.
[sqlTypeId] :: SqlType a -> SqlTypeId

-- | 'sqlTypeSqlSize will be compared to the <tt>colSize</tt> field found
--   in the <a>SqlColDesc</a> return by <tt>describeTable</tt> when
--   determining whether a column type change is required when migrating
--   the database.
[sqlTypeSqlSize] :: SqlType a -> Maybe Int

-- | A function for converting Haskell values of this type into values to
--   be stored in the database.
[sqlTypeToSql] :: SqlType a -> a -> SqlValue

-- | A function for converting values of this are stored in the database
--   into Haskell values. This function should return 'Left
--   RowDataErrorReason' to indicate an error if the conversion is
--   impossible. Otherwise it should return <a>Right</a> the corresponding
--   <tt>a</tt> value.
[sqlTypeFromSql] :: SqlType a -> SqlValue -> Either RowDataErrorReason a

-- | <a>serial</a> defines a 32-bit auto-incrementing column type. This
--   corresponds to the <a>SERIAL</a> type in PostgreSQL.
serial :: SqlType Int32

-- | <a>bigserial</a> defines a 64-bit auto-incrementing column type. This
--   corresponds to the <a>BIGSERIAL</a> type in PostgresSQL.
bigserial :: SqlType Int64

-- | <a>text</a> defines a fixed length text field type. This corresponds
--   to a "CHAR(len)" type in SQL.
text :: Int -> SqlType Text

-- | <a>varText</a> defines a variable text field type with a max length.
--   This corresponds to a "VARCHAR(len)" type in SQL.
varText :: Int -> SqlType Text

-- | <a>unboundedText</a> defines a fixed length text field type. This
--   corresponds to a <a>TEXT</a> type in PostgreSQL.
unboundedText :: SqlType Text

-- | <a>integer</a> defines a 32-bit integer type. This corresponds to the
--   <a>INTEGER</a> type in SQL.
integer :: SqlType Int32

-- | <a>bigInteger</a> defines a 64-bit integer type. This corresponds to
--   the <a>BIGINT</a> type in SQL.
bigInteger :: SqlType Int64

-- | <a>double</a> defines a floating point numeric type. This corresponds
--   to the "DOUBLE PRECISION" type in SQL.
double :: SqlType Double

-- | <a>boolean</a> defines a True/False boolean type. This corresponds to
--   the <a>BOOLEAN</a> type in SQL.
boolean :: SqlType Bool

-- | <a>date</a> defines a type representing a calendar date (without time
--   zone). It corresponds to the <a>DATE</a> type in SQL.
date :: SqlType Day

-- | <a>timestamp</a> defines a type representing a particular point in
--   time (without time zone). It corresponds to the "TIMESTAMP with time
--   zone" type in SQL.
--   
--   Note: This is NOT a typo. The "TIMESTAMP with time zone" type in SQL
--   does not include any actual time zone information. For an excellent
--   explanation of the complexities involving this type, please see Chris
--   Clark's blog post about it:
--   <a>http://blog.untrod.com/2016/08/actually-understanding-timezones-in-postgresql.html</a>
timestamp :: SqlType UTCTime

-- | <a>textSearchVector</a> defines a type for indexed text searching. It
--   corresponds to the <a>TSVECTOR</a> type in PostgreSQL.
textSearchVector :: SqlType Text

-- | Migration Guide: <tt>convertSqlType</tt> retains the same name
--   
--   <a>convertSqlType</a> changes the Haskell type used by a
--   <a>SqlType</a> in the same manner as <a>maybeConvertSqlType</a> in
--   cases where an <tt>a</tt> can always be converted to a <tt>b</tt>.
convertSqlType :: (b -> a) -> (a -> b) -> SqlType a -> SqlType b

-- | Migration Guide: <tt>maybeConvertSqlType</tt> has been replaced with
--   <tt>tryConvertSqlType</tt>, which allows an error message to be
--   returned when conversion fails.
--   
--   <a>maybeConvertSqlType</a> changes the Haskell type used by a
--   <a>SqlType</a> without changing the column type that will be used in
--   the database schema. The functions given will be used to convert the
--   now Haskell type to and from the original type when reading and
--   writing values from the database. When reading an <tt>a</tt> value
--   from the database, the conversion function should produce
--   <a>Nothing</a> if the value cannot be successfully converted to a
--   <tt>b</tt>.
maybeConvertSqlType :: (b -> a) -> (a -> Maybe b) -> SqlType a -> SqlType b

-- | MigrationGuide: <tt>TableParams</tt> no longer exists. See the
--   migration guide for <a>mkTableDefinition</a>
--   
--   <a>TableParams</a> is the simplest way to make a
--   <a>TableDefinition</a>. You can use <a>mkTableDefinition</a> to make a
--   definition from the simplified params. Where <a>TableDefinition</a>
--   requires the <a>tableFields</a>, <a>tableFromSql</a>, and
--   <a>tableToSql</a> to all be defined separately and kept in sync,
--   <a>TableParams</a> provides a single <a>tblMapper</a> field that
--   specifies all three simultaneously and ensures they are consistent
--   with one another.
data TableParams readEntity writeEntity key
TableParams :: String -> RelationalMap writeEntity readEntity -> [String] -> PrimaryKey key -> (readEntity -> key) -> TableComments () -> TableParams readEntity writeEntity key

-- | The name of the table in the database
[tblName] :: TableParams readEntity writeEntity key -> String

-- | The relational mapping that defines how the Haskell entity type is
--   converted both to and from sql. The fields utilized in the mapping are
--   used to automatically build the list of <tt>FieldDefinitions</tt> that
--   define the structure of the table in the database.
[tblMapper] :: TableParams readEntity writeEntity key -> RelationalMap writeEntity readEntity

-- | A list of any columns that may be deleted from the table by Orville.
--   (Orville will never delete a column without being told it is safe)
[tblSafeToDelete] :: TableParams readEntity writeEntity key -> [String]

-- | A function to set the key on the entity
[tblPrimaryKey] :: TableParams readEntity writeEntity key -> PrimaryKey key

-- | A function to get the key on the entity
[tblGetKey] :: TableParams readEntity writeEntity key -> readEntity -> key

-- | Any comments that might be interesting for developers to see. These
--   comments will get printed in the log if there is an erro while
--   attempting to migrate the table.
[tblComments] :: TableParams readEntity writeEntity key -> TableComments ()

-- | Migration guide: This type has been replaced with the
--   <tt>SqlMarshaller</tt> type in the new orville. The interface is
--   similar, though the names of the functions have been updated in many
--   cases. See the migration guides for those functions to find their new
--   names.
data RelationalMap a b

-- | Migration Guide: The fields in new orville's <tt>SqlMarshaller</tt>
--   are somewhat more sophisticated than those of a
--   <tt>RelationalMap</tt>. The <a>fields</a> function is no longer
--   offered with this simple interface as a result, but the
--   <tt>foldMarshallerFields</tt> function can be used in combination with
--   the <tt>collectFromField</tt> helper to collect the desired
--   information from each field.
fields :: RelationalMap a b -> [SomeField]

-- | Migration Guide: <tt>mapAttr</tt> has been renamed to
--   <tt>marshallNested</tt>
mapAttr :: (a -> b) -> RelationalMap b c -> RelationalMap a c

-- | Migration Guide: <tt>mapField</tt> has been removed, though its
--   functional equivalent is <tt>marshallReadOnlyField</tt>
mapField :: FieldDefinition nullability a -> RelationalMap a a

-- | Migration Guide: <tt>attrField</tt> has been renamed to
--   <tt>marshallField</tt>
attrField :: (a -> b) -> FieldDefinition nullability b -> RelationalMap a b

-- | Migration Guide: <tt>maybeMapper</tt> has been renamed to
--   <tt>marshallMaybe</tt>
maybeMapper :: RelationalMap a b -> RelationalMap (Maybe a) (Maybe b)

-- | Migration Guide: <tt>prefixMap</tt> has been renamed to
--   <tt>prefixMarshaller</tt>
prefixMap :: String -> RelationalMap a b -> RelationalMap a b

-- | Migration Guide: <tt>partialMap</tt> has been renamed to
--   <tt>marshallPartial</tt>
partialMap :: RelationalMap a (Either String a) -> RelationalMap a a

-- | Migration Guide: <tt>readOnlyMap</tt> has been renamed to
--   <tt>marshallReadOnly</tt>
readOnlyMap :: RelationalMap a b -> RelationalMap c b

-- | Migration Guide: <tt>readOnlyField</tt> has been renamed to
--   <tt>marshallReadOnlyField</tt>
readOnlyField :: FieldDefinition nullability a -> RelationalMap b a

-- | Migration Guide: <tt>OrvilleEnv</tt> has been renamed to
--   <tt>OrvilleState</tt>. It no longer has any type paremeters. The
--   connection type is fixed and cannot be changed.
--   
--   <a>OrvilleEnv</a> tracks all the environment information required for
--   an 'OrvilleT conn m' Monad to operate. Use <a>newOrvilleEnv</a> to
--   construct one.
data OrvilleEnv conn

-- | Migration Guide: <tt>newOrvilleEnv</tt> has been renamed to
--   <tt>newOrvilleState</tt>. The new function requires a parameter to be
--   passed before the connection pool to specify the level of detail to be
--   used when Orville reports errors.
--   
--   <a>newOrvilleEnv</a> initialized an <a>OrvilleEnv</a> for service. The
--   connection pool provided will be used to obtain connections to the
--   database ase required. You can use the <a>createConnectionPool</a>
--   utility function to create a connection pool to a PosgreSQL server.
newOrvilleEnv :: Pool conn -> OrvilleEnv conn

-- | Migration Guide: <tt>setStartTransactionSQL</tt> has been renamed to
--   <tt>setBeginTransactionExpr</tt>
setStartTransactionSQL :: String -> OrvilleEnv conn -> OrvilleEnv conn

-- | Migration Guide: <tt>aroundRunningQuery</tt> has been renamed to
--   <tt>addSqlExecutionCallback</tt>
aroundRunningQuery :: (forall a. QueryType -> String -> IO a -> IO a) -> OrvilleEnv conn -> OrvilleEnv conn

-- | Migration Guide: <tt>addTransactionCallBack</tt> retains the same name
addTransactionCallBack :: (TransactionEvent -> IO ()) -> OrvilleEnv conn -> OrvilleEnv conn
ormEnvPool :: OrvilleEnv conn -> Pool conn
data TransactionEvent
TransactionStart :: TransactionEvent
TransactionCommit :: TransactionEvent
TransactionRollback :: TransactionEvent

-- | Migration Guide: <tt>OrvilleT</tt> has been removed. In its place you
--   can simply use a <tt>ReaderT OrvilleState</tt>. If you have another
--   <tt>ReaderT</tt> layer in your monad stack you can add the
--   <tt>OrvilleState</tt> to the reader context for that layer instead,
--   which is more efficient than having multiple <tt>ReaderT</tt> layers.
--   If you have a simple case of <tt>OrvilleT conn IO</tt> the new Orville
--   offers a simpler <tt>Orville</tt> monad (not a transformer) to get you
--   started.
data OrvilleT conn m a
unOrvilleT :: OrvilleT conn m a -> ReaderT (OrvilleEnv conn) m a
data SqlValue

-- | Migration Guide: <tt>HasOrvilleContext</tt> has been renamed to
--   <tt>HasOrvilleState</tt>. <tt>getOrvilleEnv</tt> and
--   <tt>localOrvilleEnv</tt> have been renamed to <tt>askOrvilleState</tt>
--   and <tt>localOrvilleState</tt>.
--   
--   <a>HasOrvilleContext</a> defines the operations that must be available
--   in your own monad for managing the connection pool that Orville
--   functions will use to access the database and manage transaction
--   state. In most cases you can include <a>OrvilleT</a> in your Monad
--   stack and then automatically derive an instance of
--   <a>HasOrvilleContext</a>.
--   
--   You could also provide your own implementations of these functions
--   instead of using <a>OrvilleT</a>, if that is the easiest approach for
--   your Monad.
class IConnection conn => HasOrvilleContext conn m | m -> conn

-- | getOrvilleEnv fetches the Orville environment from the Monad context.
--   Analogous to <a>ask</a> from the <tt>Reader</tt> monad.
getOrvilleEnv :: HasOrvilleContext conn m => m (OrvilleEnv conn)
localOrvilleEnv :: HasOrvilleContext conn m => (OrvilleEnv conn -> OrvilleEnv conn) -> m a -> m a

-- | Migration Guide: <tt>MonadOrville</tt> retains the same name, but the
--   <tt>conn</tt> parameter has been removed. <tt>MonadFail</tt> and
--   <tt>MonadThrow</tt> have been removed as superclass constraints.
--   
--   <a>MonadOrville</a> does not have any methods of its own. Instead it
--   brings all the typeclass constraints required by Orville functions
--   that need to access the database into a single typeclass. In some
--   cases you can include <a>OrvilleT</a> in your Monad stack and then
--   automatically derive an instance of <a>MonadOrville</a>. However, more
--   likely you are using some third party monad somewhere in your stack
--   that does not han a <a>MonadOrvilleControl</a> instance. In this case
--   you won't be able to derive <a>MonadOrville</a>, but providing a
--   simple empty instance will do:
--   
--   <pre>
--   instance O.MonadOrville Postgres.Connection MyMonad
--   
--   </pre>
class (Monad m, MonadIO m, HasOrvilleContext conn m, MonadThrow m, MonadOrvilleControl m, MonadFail m) => MonadOrville conn m

-- | Migration Guide: <tt>runOrville</tt> now operates on the concrete
--   <tt>Orville</tt> monad becase <tt>OrvilleT</tt> has been removed.
--   Assuming you are replacing usages of <tt>OrvilleT</tt> with
--   <tt>ReaderT</tt> you will want to replace usages of
--   <tt>runOrville</tt> with <tt>runReaderT</tt>.
runOrville :: OrvilleT conn m a -> OrvilleEnv conn -> m a

-- | Migration Guide: <tt>mapOrvilleT</tt> has been removed because
--   <tt>OrvilleT</tt> has been removed. If you're replacing
--   <tt>OrvilleT</tt> with <tt>ReaderT</tt> then <tt>mapOrvilleT</tt>
--   should be replaced with <tt>mapReaderT</tt>.
mapOrvilleT :: Monad n => (m a -> n b) -> OrvilleT conn m a -> OrvilleT conn n b

-- | Migration Guide: <tt>MonadOrvilleControl</tt> retains the same name.
--   The <tt>liftFinally</tt> member has been removed. There are new
--   <tt>liftCatch</tt> and <tt>liftMask</tt> members that must be
--   implemented, however. Instances of the new
--   <tt>MonadOrvilleControl</tt> are provided for <tt>IO</tt> and
--   <tt>ReaderT</tt>. Helper functions for implmenting the members via
--   <tt>UnliftIO</tt> can be found in
--   <tt>Orville.PostgreSQL.UnliftIO</tt>.
--   
--   <a>MonadOrvilleControl</a> provides an interface for the kinds of IO
--   operations that Orville functions need to lift into the Monad
--   providing the <a>MonadOrville</a> instance. This typeclass allows
--   users to provide their own lifting strategies in case the Monad stack
--   in question has special needs. If you are only using <a>ReaderT</a>
--   and <a>OrvilleT</a> layers in your monad stack, you can probably
--   implement this for your own Monad wrapper type using the provided
--   default functions and providing functions to wrap and unwrapper your
--   Monad layer:
--   
--   <pre>
--   instance MonadOrvilleControl MyMonad where
--     liftWithConnection = defaultLiftWithConnection wrapMyMonad unWrapMyMonad
--     liftFinally = defaultLiftFinally wrapMyMonad unWrapMyMonad
--   
--   </pre>
--   
--   If you are using transformers in your monad stack beyond
--   <a>ReaderT</a>, they probably don't provide <a>MonadOrvilleControl</a>
--   instances (e.g. third party libraries). In this case, see
--   <a>MonadUnliftIO</a> for more help. If you're still stuck (because
--   your library doesn't support <tt>MonadTransControl</tt>), try
--   <a>MonadBaseControl</a> instead. If you're *still* stuck after that,
--   please file an issue on Github at
--   <a>https://github.com/flipstone/orville</a> so we can can help out!
class MonadOrvilleControl m
liftWithConnection :: MonadOrvilleControl m => (forall a. (conn -> IO a) -> IO a) -> (conn -> m b) -> m b
liftFinally :: MonadOrvilleControl m => (forall a b. IO a -> IO b -> IO a) -> m c -> m d -> m c

-- | Migration Guide: <tt>defaultLiftWithConnection</tt> has been removed.
--   In its place you can use either the <tt>ReaderT</tt> instance of
--   <tt>MonadOrvilleControl</tt> or the helpers in
--   <tt>Orville.PostgreSQL.UnliftIO</tt>.
--   
--   defaultLiftWithConnection provides a simple definition of
--   <a>liftWithConnection</a> for <a>MonadOrvilleControl</a> instances
--   when the Monad in question is a wrapper around a type that already
--   implements <a>MonadOrvilleControl</a>
defaultLiftWithConnection :: MonadOrvilleControl m => (forall a. m a -> n a) -> (forall a. n a -> m a) -> (forall a. (conn -> IO a) -> IO a) -> (conn -> n b) -> n b

-- | Migration Guide: <tt>defaultLiftWithConnection</tt> has been removed
--   (along with <tt>liftFinally</tt>)
--   
--   defaultLiftFinally provides a simple definition of
--   <a>liftWithConnection</a> for <a>MonadOrvilleControl</a> instances
--   when the Monad in question is a wrapper around a type that already
--   implements <a>MonadOrvilleControl</a>
defaultLiftFinally :: MonadOrvilleControl m => (forall a. m a -> n a) -> (forall a. n a -> m a) -> (forall a b. IO a -> IO b -> IO a) -> n c -> n d -> n c
data QueryType
SelectQuery :: QueryType
InsertQuery :: QueryType
UpdateQuery :: QueryType
DeleteQuery :: QueryType
DDLQuery :: QueryType

-- | Migration Guide: <tt>withCachedConnection</tt> has been renamed to
--   <tt>withConnection_</tt>
--   
--   Runs an action with a cached connection. Without using this, or
--   wrapping calls in a transaction using <a>withTransaction</a>,
--   successive calls to functions like <tt>insertRecord</tt> and
--   <tt>updateRecord</tt> are *not* guaranteed to occur on the same
--   connection.
withCachedConnection :: MonadOrville conn m => m a -> m a

-- | Migration Guide: <tt>withTransaction</tt> retains the same name.
withTransaction :: MonadOrville conn m => m a -> m a

-- | Migration Guide: <tt>ColumnFlag</tt> has been removed. Depending on
--   flag constructor there may or may not be a replacement.
--   
--   <tt>ColumnDefault</tt> - replaced by the <tt>setDefaultValue</tt>
--   function in new orville <tt>Unique</tt> - replaced by the
--   <tt>addUniqueConstraint</tt> function in new orville
--   <tt>References</tt> - replaced by the <tt>addForeignKeyConstraint</tt>
--   function in new orville <tt>ColumnDescription</tt> - removed
--   <tt>AssignedByDatabase</tt> - removed, though many cases are handled
--   by <tt>marshallReadOnlyField</tt>
data ColumnFlag
Default :: a -> ColumnFlag
Unique :: ColumnFlag
References :: TableDefinition readEntity writeEntity key -> FieldDefinition nullability key -> ColumnFlag
ColumnDescription :: String -> ColumnFlag
AssignedByDatabase :: ColumnFlag
class ColumnDefault a
toColumnDefaultSql :: ColumnDefault a => a -> String
data Now
Now :: Now

-- | Migration Guide: The signature of the <tt>FieldDefinition</tt> type
--   has not changed, but many of the constructors and accessors have. See
--   the migration guides on individual functions for more info.
data FieldDefinition nullability a

-- | <a>Nullable</a> is a values-less type used to track that a
--   <a>FieldDefinition</a> represents a field that is marked nullable in
--   the database schema. See the <a>Nullability</a> type for the
--   value-level representation of field nullability.
data Nullable

-- | 'NotNull is a values-less type used to track that a
--   <a>FieldDefinition</a> represents a field that is marked not-null in
--   the database schema. See the <a>Nullability</a> type for the
--   value-level representation of field nullability.
data NotNull

-- | <a>Nullability</a> represents whether a field will be marked as
--   <tt>NULL</tt> or 'NOT NULL' in the database schema. It is a GADT so
--   that the value constructors can be used to record this knowledge in
--   the type system as well. This allows functions that work only on
--   <a>Nullable</a> or <a>NotNull</a> fields to indicate this in their
--   type signatures as appropriate.
data Nullability nullability
[Nullable] :: Nullability Nullable
[NotNull] :: Nullability NotNull

-- | Migration Guide: <tt>isFieldNullable</tt> has been replaced with
--   <tt>fieldIsNotNullable</tt>, which has the same signture but the
--   <tt>Bool</tt> returned is the opposite.
isFieldNullable :: FieldDefinition nullability a -> Bool

-- | Migration Guide: <tt>fieldOfType</tt> is essentially unchanged in the
--   new orville.
fieldOfType :: SqlType a -> String -> FieldDefinition NotNull a

-- | Migration Guide: <tt>textField</tt> has been renamed to
--   <tt>boundedTextField</tt>. It now takes an <tt>Int32</tt> rather than
--   an <tt>Int</tt>
textField :: String -> Int -> FieldDefinition NotNull Text

-- | Migration Guide: <tt>fixedTextField</tt> retains the same name. It now
--   takes an <tt>Int32</tt> rather than an <tt>Int</tt>
fixedTextField :: String -> Int -> FieldDefinition NotNull Text

-- | Migration Guide: <tt>unboundedTextField</tt> retains the same name.
unboundedTextField :: String -> FieldDefinition NotNull Text

-- | Migration Guide: <tt>dayField</tt> has been renamed to
--   <tt>dateField</tt>
dayField :: String -> FieldDefinition NotNull Day

-- | Migration Guide: <tt>utcTimeField</tt> has been renamed to
--   <tt>utcTimestampField</tt>
utcTimeField :: String -> FieldDefinition NotNull UTCTime

-- | Migration guide: <tt>int32Field</tt> has been renamed to
--   <tt>integerField</tt>
int32Field :: String -> FieldDefinition NotNull Int32

-- | Migration guide: <tt>int64Field</tt> has been renamed to
--   <tt>bigIntegerField</tt>
int64Field :: String -> FieldDefinition NotNull Int64

-- | Migration guide: <tt>doubleField</tt> retains the same name.
doubleField :: String -> FieldDefinition NotNull Double

-- | Migration guide: <tt>boolField</tt> has been renamed to
--   <tt>booleanField</tt>
boolField :: String -> FieldDefinition NotNull Bool

-- | Migration guide: <tt>automaticIdField</tt> has been renamed to
--   <tt>serialField</tt>
automaticIdField :: String -> FieldDefinition NotNull Int32

-- | Migration guide: <tt>searchVectorField</tt> has been renamed to
--   <tt>textSearchVectorField</tt>
searchVectorField :: String -> FieldDefinition NotNull Text

-- | Migration Guide: <tt>nullableField</tt> retains the same name
--   
--   Makes a <a>NotNull</a> field <a>Nullable</a> by wrapping the Haskell
--   type of the field in <a>Maybe</a>. The field will be marked as
--   <tt>NULL</tt> in the database schema and the value <a>Nothing</a> will
--   be used to represent <tt>NULL</tt> values when converting to and from
--   sql.
nullableField :: FieldDefinition NotNull a -> FieldDefinition Nullable (Maybe a)

-- | Migration Guide: <tt>foreignKeyField</tt> has been removed. It is
--   replaced by <tt>addForeignKeyConstraint</tt> which adds a foreign key
--   constraint to an existing <tt>FieldDefinition</tt>.
foreignKeyField :: String -> TableDefinition readEntity writeEntity key -> FieldDefinition nullability key -> FieldDefinition nullability key

-- | Migration Guide: <tt>withFlag</tt> has been removed. See the migration
--   guide on <a>ColumnFlag</a> regarding the new API.
withFlag :: FieldDefinition nullability a -> ColumnFlag -> FieldDefinition nullability a

-- | Migration Guide: <tt>withName</tt> has been removed.
withName :: FieldDefinition nullability a -> String -> FieldDefinition nullability a

-- | Migration Guide: <tt>withConversion</tt> has been replaced with
--   <tt>convertField</tt>, whose arguments are flipped from those of
--   <tt>withConversion</tt>. Note there is also now a <tt>coerceField</tt>
--   function that can be used with <tt>newtype</tt> wrappers, provided the
--   constructor is available where <tt>coerceField</tt> is used.
withConversion :: FieldDefinition nullability a -> (SqlType a -> SqlType b) -> FieldDefinition nullability b

-- | Migration Guide: <tt>fieldFromSql</tt> has been replaced with
--   <tt>fieldValueFromSqlValue</tt>
fieldFromSql :: FieldDefinition nullability a -> FromSql a

-- | Migration Guide: <tt>fieldToSqlValue</tt> has been renamed to
--   <tt>fieldValueToSqlValue</tt>
fieldToSqlValue :: FieldDefinition nullability a -> a -> SqlValue
data SomeField
SomeField :: FieldDefinition nullability a -> SomeField

-- | Migration Guide: <tt>withPrefix</tt> has been replaced by
--   <tt>prefixField</tt> whose arguments are flipped relative to
--   <tt>withPrefix</tt>
withPrefix :: FieldDefinition nullability a -> String -> FieldDefinition nullability a
fieldName :: FieldDefinition nullability a -> String
fieldType :: FieldDefinition nullability a -> SqlType a

-- | <tt>fieldFlags</tt> has been removed. See the new
--   <tt>fieldDefaultValue</tt> and <tt>fieldTableConstraints</tt>
--   functions
fieldFlags :: FieldDefinition nullability a -> [ColumnFlag]
data IndexDefinition
IndexDefinition :: String -> Bool -> String -> String -> IndexDefinition
[indexName] :: IndexDefinition -> String
[indexUnique] :: IndexDefinition -> Bool
[indexTable] :: IndexDefinition -> String
[indexBody] :: IndexDefinition -> String

-- | Migration Guide: <tt>uniqueIndex</tt> no longer requires a name to be
--   specified. Migration will be done automatically by inspecting the
--   structure of the indexes that exist in the database. It also no longer
--   accepts a <tt>TableDefinition</tt> at the time of creating the
--   <tt>IndexDefinition</tt>. Instead you should use
--   <tt>addTableIndexes</tt> to add the <tt>IndexDefinition</tt> to the
--   <tt>TableDefinition</tt> for the table that you wish to index.
--   
--   If you wish to specify the index name explicitly, you can use
--   <tt>uniqueNamedIndex</tt> instead. If you do so, index migration will
--   be managed by comparing to the names of existing indexes rather than
--   checking that the index structure matches the Haskell definition.
uniqueIndex :: String -> TableDefinition readEntity writeEntity key -> [SomeField] -> IndexDefinition

-- | Migration Guide: <tt>simpleIndex</tt> has been renamed to
--   <tt>nonUniqueIndex</tt>. It no longer requires a name to be specified.
--   Migration will be done automatically be inspecting the structure of
--   the indexes that exist in the database. It also no longer accepts a
--   <tt>TableDefinition</tt> at the time of creating the
--   <tt>IndexDefinition</tt>. Instead you should use
--   <tt>addTableIndexes</tt> to add the <tt>IndexDefinition</tt> to the
--   <tt>TableDefinition</tt> for the table that you wish to index.
--   
--   If you wish to specify the index name explicitly, you can use
--   <tt>nonUniqueNamedIndex</tt> instead. If you do so, index migration
--   will be managed by comparing to the names of existing indexes rather
--   than checking that the index structure matches the Haskell definition.
simpleIndex :: String -> TableDefinition readEntity writeEntity key -> [SomeField] -> IndexDefinition

-- | Works much the same as <a>simpleIndex</a> but takes a list of strings
--   that are the conditions of a where clause on index creation for
--   partial indexes
simplePartialIndex :: String -> TableDefinition readEntity writeEntity key -> [SomeField] -> [String] -> IndexDefinition

-- | Works much the same as <a>uniqueIndex</a> but takes a list of strings
--   that are the conditions of a where clause on index creation for
--   partial indexes
uniquePartialIndex :: String -> TableDefinition readEntity writeEntity key -> [SomeField] -> [String] -> IndexDefinition
data ConstraintDefinition
ConstraintDefinition :: String -> String -> String -> ConstraintDefinition
[constraintName] :: ConstraintDefinition -> String
[constraintTable] :: ConstraintDefinition -> String
[constraintBody] :: ConstraintDefinition -> String
data SequenceDefinition
SequenceDefinition :: String -> Maybe Int -> Maybe Int -> Maybe Int -> Maybe Int -> Maybe Int -> Bool -> SequenceDefinition
[sequenceName] :: SequenceDefinition -> String
[sequenceIncrement] :: SequenceDefinition -> Maybe Int
[sequenceMinValue] :: SequenceDefinition -> Maybe Int
[sequenceMaxValue] :: SequenceDefinition -> Maybe Int
[sequenceStart] :: SequenceDefinition -> Maybe Int
[sequenceCache] :: SequenceDefinition -> Maybe Int
[sequenceCycle] :: SequenceDefinition -> Bool

-- | Migration Guide: <tt>uniqueConstraint</tt> no longer accepts a name
--   parameter. Instead the constraint is migrated automatically based on
--   the structure of existing constraints found in the database. It also
--   no longer accepts a <tt>TableDefinition</tt>. Instead you should use
--   <tt>addTableConstraints</tt> to add the <tt>ConstraintDefinition</tt>
--   to the table that you wish to apply the constraint to.
uniqueConstraint :: String -> TableDefinition readEntity writeEntity key -> [SomeField] -> ConstraintDefinition

-- | Migration Guide: <tt>dropConstraint</tt> has been removed. Constraints
--   are now dropped automatically during auto-migration when they are
--   removed from the <tt>TableDefinition</tt>.
dropConstraint :: TableDefinition readEntity writeEntity key -> String -> SchemaItem
data FromSql a
data FromSqlError

-- | Captures a failure in the translation of a SQL value from a particular
--   field to it's corresponding Haskell values.
RowDataError :: !RowDataErrorDetails -> FromSqlError

-- | An expected column was not returned by the database
MissingColumn :: !MissingColumnDetails -> FromSqlError

-- | A conversion between haskell representations failed at a point where
--   we don't know what column the value came from. This is the case when
--   using the <tt>partialMap</tt> combinator.
ConversionError :: !ConversionErrorDetails -> FromSqlError
data RowDataErrorDetails
RowDataErrorDetails :: !RowDataErrorReason -> !String -> ![(String, SqlValue)] -> RowDataErrorDetails
[rowErrorReason] :: RowDataErrorDetails -> !RowDataErrorReason

-- | Column name for the erroneous value
[rowErrorColumnName] :: RowDataErrorDetails -> !String

-- | Primary keys. Empty if not known
[rowErrorPrimaryKeys] :: RowDataErrorDetails -> ![(String, SqlValue)]
data RowDataErrorReason

-- | Sql value has a different type than expected
TypeMismatch :: !String -> !String -> RowDataErrorReason

-- | An integer value was outside the expected bounds.
IntegralOutOfBounds :: !Integer -> !Integer -> !Integer -> RowDataErrorReason

-- | Generic decoding failure
DecodingFailure :: !String -> RowDataErrorReason
data MissingColumnDetails
MissingColumnDetails :: !String -> ![String] -> MissingColumnDetails
[missingColumn] :: MissingColumnDetails -> !String
[actualColumns] :: MissingColumnDetails -> ![String]
data ConversionErrorDetails
ConversionErrorDetails :: !String -> ![(String, SqlValue)] -> ConversionErrorDetails
[convErrorReason] :: ConversionErrorDetails -> !String

-- | Primary key value(s). Empty if not known
[convErrorPrimaryKeys] :: ConversionErrorDetails -> ![(String, SqlValue)]

-- | Shows the error in a way that should not contain any potentially
--   sensitive data. This is used for the <a>Show</a> instance.
showFromSqlErrorMinimal :: FromSqlError -> String

-- | Shows the error in a way appropriate for logging within an
--   application. The resulting string contains information that is useful
--   for debugging but is potentially undesirable to expose outside of the
--   application (such as primary key values).
showFromSqlErrorForLogging :: FromSqlError -> String

-- | User friendly identifier labels for <tt>SqlValues</tt>
showSqlValueType :: SqlValue -> String
class ColumnSpecifier col
selectForm :: ColumnSpecifier col => col -> SelectForm
col :: (ColumnSpecifier col, Convertible SqlValue a) => col -> FromSql a
data ToSql a b
getField :: Convertible a SqlValue => (entity -> a) -> ToSql entity ()
getComponent :: (entity -> a) -> ToSql a () -> ToSql entity ()

-- | Migration Guide: <tt>SchemaItem</tt> retains the same name. The
--   <tt>Index</tt>, <tt>DropIndex</tt>, <tt>Constraint</tt> and
--   <tt>DropConstraint</tt> constructors have been removed. These items
--   are now added to the <tt>TableDefinition</tt> via
--   <tt>addTableConstraints</tt> and <tt>addTableIndexes</tt>. The
--   remaining constructors have been prefixed with the word
--   <tt>Schema</tt> (e.g. <tt>Table</tt> has been renamed to
--   <tt>SchemaTable</tt>). There is no explicit replacement for
--   <tt>DropIndex</tt> and <tt>DropConstraint</tt>. Orville will
--   automatically drop indexes and constraints that are no longer
--   mentioned on the <tt>TableDefinition</tt> for any tables that it
--   migrates.
data SchemaItem
Table :: TableDefinition readEntity writeEntity key -> SchemaItem
DropTable :: String -> SchemaItem
Index :: IndexDefinition -> SchemaItem
DropIndex :: String -> SchemaItem
Constraint :: ConstraintDefinition -> SchemaItem
DropConstraint :: String -> String -> SchemaItem
Sequence :: SequenceDefinition -> SchemaItem
DropSequence :: String -> SchemaItem

-- | Migration Guide: <tt>SchemaDefinition</tt> has been removed. Use
--   <tt>[SchemaItem]</tt> instead.
type SchemaDefinition = [SchemaItem]

-- | Migration Guide: <tt>Record</tt> has been removed. It's recommended
--   that you create a separate record key type for each of your entities
--   instead.
type Record = Int
type CreatedAt = UTCTime
type UpdatedAt = UTCTime
type OccurredAt = UTCTime
data TableComments a
noComments :: TableComments ()
say :: String -> (Int, Int, Int) -> String -> TableComments ()
data WhereCondition

-- | Migration Guide: <tt>whereAnd</tt> has been removed. Use the binary
--   function <tt>andExpr</tt> to combine <tt>BooleanExpr</tt> expressions
--   instead. <tt>andExpr</tt> is also available as the operator
--   <tt>(.&amp;&amp;)</tt>
whereAnd :: [WhereCondition] -> WhereCondition

-- | Migration Guide: <tt>whereOr</tt> has been removed. Use the binary
--   function <tt>orExpr</tt> to combine <tt>BooleanExpr</tt> expressions
--   instead. <tt>orExpr</tt> is also available as the operator
--   <tt>(.||)</tt>
whereOr :: [WhereCondition] -> WhereCondition

-- | Migration Guide: <tt>whereIn</tt> has been renamed to
--   <tt>fieldIn</tt>. It now takes a <tt>NonEmpty</tt> list of values to
--   reflect this is a requirement in SQL.
whereIn :: FieldDefinition nullability a -> [a] -> WhereCondition

-- | Migration Guide: <tt>whereLike</tt> has been renamed to
--   <tt>fieldLike</tt>. It now takes a <tt>T.Text</tt> value rather than a
--   <tt>String</tt>.
whereLike :: FieldDefinition nullability a -> String -> WhereCondition

-- | Migration Guide: <tt>whereLikeInsensitive</tt> has been renamed to
--   <tt>fieldLikeInsensitive</tt>. It now takes a <tt>T.Text</tt> value
--   rather than a <tt>String</tt>.
whereLikeInsensitive :: FieldDefinition nullability a -> String -> WhereCondition

-- | Migration Guide: <tt>whereNotIn</tt> has been renamed to
--   <tt>fieldNotIn</tt>. It now takes a <tt>NonEmpty</tt> list of values
--   to reflect this is a requirement in SQL.
whereNotIn :: FieldDefinition nullability a -> [a] -> WhereCondition

-- | Migration Guide: <tt>whereQualified</tt> has been removed. If you need
--   qualified column references you can use the SQL building functions
--   found in <tt>Orville.PostgreSQL.Expr</tt> to build them. The
--   <tt>qualifyColumn</tt> function can be used to qualify column
--   references in that context. <tt>BooleanExpr</tt> values built directly
--   this way can be easily used in conjuction with other helpers such as
--   <tt>fieldEquals</tt> which also build <tt>BooleanExpr</tt> values
--   themselves.
whereQualified :: TableDefinition a b c -> WhereCondition -> WhereCondition

-- | Migration Guide: <tt>whereRaw</tt> has been removed. In its place you
--   should use the more general functions such as
--   <tt>unsafeSqlExpression</tt> or <tt>unsafeRawSql</tt> in the
--   <tt>Orville.PostgreSQL.Raw.RawSql</tt> module to build a
--   <tt>BooleanExpr</tt>.
whereRaw :: String -> [SqlValue] -> WhereCondition

-- | Migration Guide: <tt>whereToSql</tt> has been removed. It is replaced
--   by the more general <tt>toBytesAndParams</tt> function in
--   <tt>Orville.PostgreSQL.Raw.RawSql</tt>.
whereToSql :: [WhereCondition] -> (String, [SqlValue])

-- | Migration Guide: <tt>isNull</tt> has been renamed to
--   <tt>fieldIsNull</tt>
isNull :: FieldDefinition Nullable a -> WhereCondition

-- | Migration Guide: <tt>isNotNull</tt> has been renamed to
--   <tt>fieldIsNotNull</tt>
isNotNull :: FieldDefinition Nullable a -> WhereCondition
(.==) :: FieldDefinition nullability a -> a -> WhereCondition
(.<>) :: FieldDefinition nullability a -> a -> WhereCondition
(.<-) :: FieldDefinition nullability a -> [a] -> WhereCondition
(%==) :: FieldDefinition nullability a -> a -> WhereCondition
(.>) :: FieldDefinition nullability a -> a -> WhereCondition
(.>=) :: FieldDefinition nullability a -> a -> WhereCondition
(.<) :: FieldDefinition nullability a -> a -> WhereCondition
(.<=) :: FieldDefinition nullability a -> a -> WhereCondition
data SelectOptions
SelectOptions :: First Bool -> [WhereCondition] -> [OrderByClause] -> First Int -> First Int -> [GroupByClause] -> SelectOptions
[selectDistinct] :: SelectOptions -> First Bool
[selectOptWhere] :: SelectOptions -> [WhereCondition]
[selectOptOrder] :: SelectOptions -> [OrderByClause]
[selectOptLimit] :: SelectOptions -> First Int
[selectOptOffset] :: SelectOptions -> First Int
[selectOptGroup] :: SelectOptions -> [GroupByClause]
where_ :: WhereCondition -> SelectOptions
distinct :: SelectOptions
order :: ToOrderBy a => a -> SortDirection -> SelectOptions
limit :: Int -> SelectOptions
offset :: Int -> SelectOptions
groupBy :: ToGroupBy a => a -> SelectOptions
selectOptionsToSql :: SelectOptions -> (String, [SqlValue])

-- | An associative operation.
(<>) :: Semigroup a => a -> a -> a
infixr 6 <>
data FieldUpdate
fieldUpdate :: FieldDefinition nullability a -> a -> FieldUpdate
(.:=) :: FieldDefinition nullability a -> a -> FieldUpdate
data OrderByClause
OrderByClause :: String -> [SqlValue] -> SortDirection -> OrderByClause
data SortDirection
Ascending :: SortDirection
Descending :: SortDirection

-- | Migration Guide: <tt>migrateSchema</tt> has been renamed to
--   <tt>autoMigrateSchema</tt>
--   
--   migrateSchema will attempt to make changes to the actual database
--   schema that it it matches the provided SchemaDefinition. Unsafe
--   migrations such as dropping tables or columns are never attempted
--   unless the SchemaDefinition explicitly states that the items are safe
--   to drop. Column types may be changed, but will fail if the database
--   cannot successfully make the request type change.
migrateSchema :: MonadOrville conn m => SchemaDefinition -> m ()
data MigrationError
MigrationLockExcessiveRetryError :: String -> MigrationError
MigrationExecutionError :: SchemaItem -> SomeException -> MigrationError

-- | Migration Guide: <tt>generateMigrationPlan</tt> retains the same name.
--   It has changed to always return a <tt>MigrationPlan</tt>. You can use
--   check whether <tt>migrationPlanSteps</tt> is as empty list if you wish
--   to determine whether any migrations will be performed by the plan.
--   
--   generateMigrationPlan inspects the state of the actual database schema
--   and constructs a plan describing what changes would be made to make it
--   match the provided SchemaDefinition. If the actual schema already
--   matches the definition, Nothing will be returned.
generateMigrationPlan :: MonadOrville conn m => SchemaDefinition -> m (Maybe MigrationPlan)

-- | Migration Guide: <tt>MigrationPlan</tt> retains the same name.
data MigrationPlan

-- | Migration Guide: <tt>MigrationItem</tt> has been renamed to
--   <tt>MigrationStep</tt>, which is now a simple <tt>RawSql</tt> wrapper.
--   You can use <tt>RawSql.toExampleBytes</tt> if you wish to render it to
--   a bytestring for display purposes.
data MigrationItem
MigrationItem :: SchemaItem -> DDL -> MigrationItem
[migrationItemSchemaItem] :: MigrationItem -> SchemaItem
[migrationItemDDL] :: MigrationItem -> DDL

-- | Migration Guide: <tt>migrationPlanItems</tt> has been renamed to
--   <tt>migrationPlanSteps</tt>
migrationPlanItems :: MigrationPlan -> [MigrationItem]
data Pagination m entity
Pagination :: [entity] -> Maybe (m (Pagination m entity)) -> Pagination m entity
[pageRows] :: Pagination m entity -> [entity]
[pageNext] :: Pagination m entity -> Maybe (m (Pagination m entity))
buildPagination :: (MonadOrville conn m, Bounded orderField, Enum orderField) => TableDefinition readEnt write key -> FieldDefinition NotNull orderField -> (readEnt -> orderField) -> Maybe WhereCondition -> Word -> m (Pagination m readEnt)

-- | Migration Guide: <tt>selectAll</tt> has been renamed to
--   <tt>findEntitiesBy</tt>
selectAll :: MonadOrville conn m => TableDefinition readEntity writeEntity key -> SelectOptions -> m [readEntity]

-- | Migration Guide: <tt>selectFirst</tt> has been renamed to
--   <tt>findFirstEntityBy</tt>
selectFirst :: MonadOrville conn m => TableDefinition readEntity writeEntity key -> SelectOptions -> m (Maybe readEntity)

-- | Migration Guide: <tt>deleteRecord</tt> has been renamed to
--   <tt>deleteEntity</tt>. Note that there are also new variant functions
--   <tt>deleteAndReturnEntity</tt> and
--   <tt>deleteEntityAndReturnRowCount</tt> that return <tt>Maybe
--   readEntity</tt> and <tt>Int</tt> respectively.
deleteRecord :: MonadOrville conn m => TableDefinition readEntity writeEntity key -> key -> m ()

-- | Migration Guide: <tt>deleteWhere</tt> has been renamed to
--   <tt>deleteEntities</tt>. It now takes a <tt>Maybe BooleanExpr</tt>
--   rather than <tt>[WhereCondition]</tt>
deleteWhere :: MonadOrville conn m => TableDefinition readEntity writeEntity key -> [WhereCondition] -> m Integer

-- | Migration Guide: <tt>findRecord</tt> has been renamed to
--   <tt>findEntity</tt>
findRecord :: MonadOrville conn m => TableDefinition readEntity writeEntity key -> key -> m (Maybe readEntity)

-- | Migration Guide: <tt>findRecords</tt> has been renamed to
--   <tt>findEntities</tt>. It now requires a <tt>NonEmpty key</tt> rather
--   than simply <tt>[key]</tt> and returns a <tt>[readEntity]</tt> instead
--   of a <tt>Map</tt>.
findRecords :: (Ord key, MonadOrville conn m) => TableDefinition readEntity writeEntity key -> [key] -> m (Map key readEntity)

-- | Migration Guide: <tt>findRecordsBy</tt> has been renamed to
--   <tt>findEntitiesBy</tt>. It no longer takes a <tt>FieldDefinition</tt>
--   to group by. Instead it simply returns a <tt>[readEntity]</tt>
findRecordsBy :: (Ord fieldValue, MonadOrville conn m) => TableDefinition readEntity writeEntity key -> FieldDefinition nullability fieldValue -> SelectOptions -> m (Map fieldValue [readEntity])

-- | Migration Guide: <tt>insertRecord</tt> has been renamed to
--   <tt>insertAndReturnEntity</tt>. Note there are also new variant
--   functions <tt>insertEntity</tt> and
--   <tt>insertEntityAndReturnRowCount</tt> that return <tt>()</tt> and
--   <tt>Int</tt> respectively.
insertRecord :: MonadOrville conn m => TableDefinition readEntity writeEntity key -> writeEntity -> m readEntity

-- | Migration Guide: <tt>insertRecordMany</tt> has been renamed to
--   <tt>insertEntities</tt>. It now requires a <tt>NonEmpty
--   writeEntity</tt> rather than <tt>[writeEntity]</tt>. Note that there
--   are also new variant functions <tt>insertAndReturnEntities</tt> and
--   <tt>insertEntitiesAndReturnRowCount</tt>.
insertRecordMany :: MonadOrville conn m => TableDefinition readEntity writeEntity key -> [writeEntity] -> m ()

-- | Migration Guide: <tt>insertRecordManyReturning</tt> has been renamed
--   to <tt>insertAndReturnEntities</tt>.
insertRecordManyReturning :: MonadOrville conn m => TableDefinition readEntity writeEntity key -> [writeEntity] -> m [readEntity]

-- | Migration Guide: <tt>updateFields</tt> has been renamed to
--   <tt>updateFieldsAndReturnRowCount</tt>, but now takes a <tt>NonEmpty
--   SetClause</tt> instead of a <tt>[Field Update]</tt> and a <tt>Maybe
--   BooleanExpr</tt> instead of a <tt>[WhereCondition]</tt>.
--   
--   <tt>updateFields</tt> still exists as a variant of this function, but
--   returns <tt>()</tt> rather than <tt>Int</tt>.
--   <tt>updateFieldsAndReturnEntities</tt> is now available as well.
updateFields :: MonadOrville conn m => TableDefinition readEntity writeEntity key -> [FieldUpdate] -> [WhereCondition] -> m Integer

-- | Migration Guide: <tt>updateRecord</tt> has been renamed to
--   <tt>updateEntity. Note that there are also new variant functions
--   </tt>updateAndReturnEntity<tt> and
--   </tt>updateEntityAndReturnRowCount@.
updateRecord :: MonadOrville conn m => TableDefinition readEntity writeEntity key -> key -> writeEntity -> m ()
sequenceNextVal :: MonadOrville conn m => SequenceDefinition -> m Int
sequenceSetVal :: MonadOrville conn m => SequenceDefinition -> Int -> m Int
sequenceCurrVal :: MonadOrville conn m => SequenceDefinition -> m Int

-- | Migration Plan: <tt>createIndexesConcurrently</tt> has been removed.
--   You should now use <tt>setIndexCreationStrategy Asynchronous</tt>
--   instead.
--   
--   createIndexesConcurrently will create the given indexes, if they do
--   not exist using the PostgreSQL concurrently feature. However, this
--   does *not* mean the the function happens concurrently. This will wait
--   for PostgreSQL to return, but other operations to the table will be
--   allowed during index creation.
--   
--   Note: PostgreSQL does not allow CREATE INDEX CONCURRENTLY to appear
--   inside of a transaction. Use this function with care.
createIndexesConcurrently :: MonadOrville conn m => [IndexDefinition] -> m ()

-- | Migration Guide: <tt>dropIndexesConcurrently</tt> has been removed.
--   
--   dropIndexesConcurrently will drop each of the given indexes with the
--   CONCURRENTLY keyword, allowing for other table operations to continue
--   while the index is dropped. However there are several caveats that
--   come with this as noted at
--   <a>https://www.postgresql.org/docs/9.6/sql-dropindex.html</a> . Much
--   like <a>createIndexesConcurrently</a> this cannot be used in a
--   transaction. But further this cannot drop indexes that support UNIQUE
--   or PRIMARY KEY constraints.
--   
--   Use this with care.
dropIndexesConcurrently :: MonadOrville conn m => [String] -> m ()


module Database.Orville.PostgreSQL.Popper
data PopError
MissingRecord :: TableDefinition readEntity writeEntity key -> PrimaryKey key -> key -> PopError
MissingRecordBy :: TableDefinition readEntity writeEntity key -> FieldDefinition nullability fieldValue -> fieldValue -> PopError
Unpoppable :: String -> PopError
data Popper a b
data Popped a
PoppedValue :: a -> Popped a
PoppedError :: PopError -> Popped a

-- | Left-to-right composition
(>>>) :: Category cat => cat a b -> cat b c -> cat a c
infixr 1 >>>

-- | Right-to-left composition
(<<<) :: Category cat => cat b c -> cat a b -> cat a c
infixr 1 <<<
abortPop :: PopError -> Popper a b
certainly :: PopError -> Popper (Maybe b) b
certainly' :: Popper a PopError -> Popper a (Maybe b) -> Popper a b
fromKern :: (a -> b) -> Popper a b
hasMany :: Ord fieldValue => TableDefinition readEntity writeEntity key -> FieldDefinition nullability fieldValue -> Popper fieldValue [readEntity]
hasManyIn :: Ord fieldValue => TableDefinition readEntity writeEntity key -> FieldDefinition nullability fieldValue -> Popper [fieldValue] (Map fieldValue [readEntity])
hasOneIn :: Ord fieldValue => TableDefinition readEntity writeEntity key -> FieldDefinition nullability fieldValue -> Popper [fieldValue] (Map fieldValue readEntity)
hasManyInWhere :: Ord fieldValue => TableDefinition readEntity writeEntity key -> FieldDefinition nullability fieldValue -> SelectOptions -> Popper [fieldValue] (Map fieldValue [readEntity])
hasManyWhere :: Ord fieldValue => TableDefinition readEntity writeEntity key -> FieldDefinition nullability fieldValue -> SelectOptions -> Popper fieldValue [readEntity]
hasOne :: Ord fieldValue => TableDefinition readEntity writeEntity key -> FieldDefinition nullability fieldValue -> Popper fieldValue (Maybe readEntity)
hasOne' :: Ord fieldValue => TableDefinition readEntity writeEntity key -> FieldDefinition nullability fieldValue -> Popper fieldValue readEntity
hasOneWhere :: Ord fieldValue => TableDefinition readEntity writeEntity key -> FieldDefinition nullability fieldValue -> SelectOptions -> Popper fieldValue (Maybe readEntity)
kern :: Popper a a
popMissingRecord :: TableDefinition readEntity writeEntity key -> FieldDefinition nullability fieldValue -> Popper fieldValue PopError
onKern :: (a -> b -> c) -> Popper b a -> Popper b c
pop :: MonadOrville conn m => Popper a b -> a -> m (Popped b)
popThrow :: MonadOrville conn m => Popper a b -> a -> m b
popFirst :: TableDefinition readEntity writeEntity key -> SelectOptions -> Popper a (Maybe readEntity)
popMany :: Popper a b -> Popper [a] [b]
onPopMany :: Popper a b -> Popper [a] [b] -> Popper a b
popMaybe :: Popper a b -> Popper (Maybe a) (Maybe b)

-- | popQuery embeds an Orville operation in a popper. It is left up to the
--   programmer to ensure that the Orville operation does not do any
--   updates to the database, but only does queries.
--   
--   The initial string argument is a description of the query to put into
--   the results of <a>explain</a>
popQuery :: String -> (forall conn m. MonadOrville conn m => m b) -> Popper a b
popRecord :: TableDefinition readEntity writeEntity key -> key -> Popper a (Maybe readEntity)
popRecord' :: TableDefinition readEntity writeEntity key -> key -> Popper a readEntity
popTable :: TableDefinition readEntity writeEntity key -> SelectOptions -> Popper a [readEntity]
explain :: Popper a b -> String
explainLines :: Popper a b -> [String]
instance GHC.Base.Functor (Database.Orville.PostgreSQL.Popper.Popper a)
instance GHC.Base.Applicative (Database.Orville.PostgreSQL.Popper.Popper a)
instance Control.Category.Category Database.Orville.PostgreSQL.Popper.Popper
instance Control.Arrow.Arrow Database.Orville.PostgreSQL.Popper.Popper
instance Control.Arrow.ArrowChoice Database.Orville.PostgreSQL.Popper.Popper
instance GHC.Base.Functor Database.Orville.PostgreSQL.Popper.Popped
instance GHC.Base.Applicative Database.Orville.PostgreSQL.Popper.Popped
instance GHC.Show.Show Database.Orville.PostgreSQL.Popper.PopError
instance GHC.Exception.Type.Exception Database.Orville.PostgreSQL.Popper.PopError

module Database.Orville.PostgreSQL.Plan.Operation

-- | <a>Operation</a> provides a stucture for building primitive operations
--   that can be incorporated into a <a>Plan</a>. An <a>Operation</a>
--   provides base case implementations of the various plan execution
--   functions. You only need to care about this type if you want to create
--   new custom operations to include in a <a>Plan</a> beyond those already
--   provided in the <a>Plan</a> api.
data Operation param result
Operation :: (forall conn m. MonadOrville conn m => param -> m (Either AssertionFailed result)) -> (forall conn m. MonadOrville conn m => [param] -> m (Either AssertionFailed (Many param result))) -> Explanation -> Explanation -> Operation param result

-- | <a>executeOperationOne</a> will be called when an plan is executed
--   with a single input parameter
[executeOperationOne] :: Operation param result -> forall conn m. MonadOrville conn m => param -> m (Either AssertionFailed result)

-- | <a>executeOperationMany</a> will be called when an plan is executed
--   with multiple input parameters (via <tt>planMany</tt>).
[executeOperationMany] :: Operation param result -> forall conn m. MonadOrville conn m => [param] -> m (Either AssertionFailed (Many param result))

-- | <a>explainOperationOne</a> will be called when producing an
--   explanation of what the plan will do when given one input parameter.
--   Plans that do not perform any interesting IO interactions should
--   generally return an empty explanation.
[explainOperationOne] :: Operation param result -> Explanation

-- | <a>explainOperationMany</a> will be called when producing an
--   explanation of what the plan will do when given multiple input
--   parameters (via <tt>planMany</tt>). Plans that do not perform any
--   interesting IO interactions should generally return an empty
--   explanation.
[explainOperationMany] :: Operation param result -> Explanation

-- | <a>AssertionFailed</a> may be returned from the execute functions of
--   an <a>Operation</a> to indicate that some expected invariant has
--   failed. For example, following a foreign key that is enforced by the
--   database only to find that no record exists. When an <a>Operation</a>
--   returns an <a>AssertionFailed</a> value during plan execution the
--   error is thrown as an exception using the <a>MonadThrow</a> instance
--   for whatever monad the plan is executing in.
data AssertionFailed

-- | <a>mkAssertionFailed</a> builds an <a>AssertionFailed</a> error from
--   an error message.
mkAssertionFailed :: String -> AssertionFailed

-- | <a>findOne</a> builds a planning primitive that finds (at most) one
--   row from the given table where the column value for the provided
--   <a>FieldDefinition</a> matches the plan's input parameter. When
--   executed on multiple parameters it fetches all rows where the field
--   matches the inputs and arbitrarily picks at most one of those rows to
--   use as the result for each input.
findOne :: Ord fieldValue => TableDefinition readEntity writeEntity key -> FieldDefinition nullability fieldValue -> Operation fieldValue (Maybe readEntity)

-- | <a>findOneWhere</a> is similar to <a>findOne</a> but allows a
--   <tt>WhereCondition</tt> to be specified that is added to the database
--   query to restrict which rows are returned.
findOneWhere :: Ord fieldValue => TableDefinition readEntity writeEntity key -> FieldDefinition nullability fieldValue -> WhereCondition -> Operation fieldValue (Maybe readEntity)

-- | <a>findAll</a> builds a planning primitive that finds all the rows
--   from the given table where the column value for the provided field
--   matches the plan's input parameter. Where executed on multiple
--   parameters all rows are fetch in a single query and then associated
--   with their respective inputs after being fetched.
findAll :: Ord fieldValue => TableDefinition readEntity writeEntity key -> FieldDefinition nullability fieldValue -> Operation fieldValue [readEntity]

-- | <a>findAllWhere</a> is similar to <a>findAll</a> but allows a
--   <tt>WhereCondition</tt> to be specified that is added to the database
--   query to restrict which rows are returned.
findAllWhere :: Ord fieldValue => TableDefinition readEntity writeEntity key -> FieldDefinition nullability fieldValue -> WhereCondition -> Operation fieldValue [readEntity]

-- | <a>findSelect</a> builds a plan <a>Operation</a> where the select that
--   is run does not use the input parameters for the plan in any way. If
--   the <a>executeOperationMany</a> function of the resulting
--   <a>Operation</a> will run the query once and use the entire result set
--   as the result each of the input parameters in turn.
findSelect :: Select row -> Operation param [row]

-- | <a>askParam</a> simply returns the paremeter given from the plan.
askParam :: Operation param param

-- | <a>assertRight</a> returns the value on the <a>Right</a> side of an
--   <a>Either</a>. If the <a>Either</a> is a <a>Left</a>, it raises
--   <a>AssertionFailed</a> with the message from the left side of the
--   either.
assertRight :: Operation (Either String a) a

-- | <a>SelectOperation</a> is a helper type for building <a>Operation</a>
--   primitives that run <a>Select</a> queries. Specifying the fields of
--   <a>SelectOperation</a> and then using the <a>selectOperation</a>
--   function to build an <a>Operation</a> is more convenient that building
--   functions to execute the queries thate are required by the
--   <a>Operation</a> type.
data SelectOperation param row result
SelectOperation :: (param -> Select row) -> ([param] -> Select row) -> Select row -> Select row -> (row -> param) -> ([row] -> result) -> SelectOperation param row result

-- | <a>selectOne</a> will be called to build the <a>Select</a> query that
--   should be run when there is a single input parameter while executing a
--   plan. Note that the "One-ness" here refers to the single input
--   parameter rather than result. See <a>produceResult</a> below for more
--   information about returning one values vs. many from a
--   <a>SelectOperation</a>.
[selectOne] :: SelectOperation param row result -> param -> Select row

-- | <a>selectMany</a> will be called to build the <a>Select</a> query that
--   should be run when there are multiple parameters while executing a
--   plan. Note that the "Many-ness" here refers to the multiple input
--   parameters rather than result. See <a>produceResult</a> below for more
--   information about returning one values vs. many from a
--   <a>SelectOperation</a>.
[selectMany] :: SelectOperation param row result -> [param] -> Select row

-- | <a>explainSelectOne</a> should show a representative query of what
--   will be returned when <a>selectOne</a> is used. No input parameter is
--   available here to build the query, however, because this value is used
--   to explain a plan without actually running it.
[explainSelectOne] :: SelectOperation param row result -> Select row

-- | <a>explainSelectMany</a> should show a representative query of what
--   will be returned when 'selectMany is used. No input parameters are
--   available here to build the query, however, because this value is used
--   to explain a plan without actually running it.
[explainSelectMany] :: SelectOperation param row result -> Select row

-- | <a>categorizeRow</a> will be used when a plan is executed with
--   multiple parameters to determine which input parameter the row should
--   be associated with.
[categorizeRow] :: SelectOperation param row result -> row -> param

-- | <a>produceResult</a> will be used convert the <tt>row</tt> type
--   returned by the <a>Select</a> queries for the operation input the
--   <tt>result</tt> type that is present as the output of the operation.
--   The input rows will be all the inputs associated with a single
--   parameter. The <tt>result</tt> type constructed here need not be a
--   single value. For instance, <a>findAll</a> uses the list type as the
--   <tt>result</tt> type and <a>findOne</a> uses <a>Maybe</a>.
[produceResult] :: SelectOperation param row result -> [row] -> result

-- | <a>selectOperation</a> builds a primitive planning <a>Operation</a>
--   using the functions given by a <a>SelectOperation</a>. If you are
--   implementing a custom operation that runs a select statement, it is
--   probably easier to use this function rather than building the
--   <a>Operation</a> functions directly.
selectOperation :: Ord param => SelectOperation param row result -> Operation param result
instance GHC.Show.Show Database.Orville.PostgreSQL.Plan.Operation.AssertionFailed
instance GHC.Exception.Type.Exception Database.Orville.PostgreSQL.Plan.Operation.AssertionFailed

module Database.Orville.PostgreSQL.Plan

-- | A <a>Plan</a> is an executable set of queries that can be executed to
--   load data from the database, using the results of prior queries as
--   input parameters to following queries in controlled ways. In
--   particular, the "controlled" aspect of this allows plans that take a
--   single input to be adapted to take multiple input parameters in a list
--   without the resulting plan executing N+1 queries. This restriction
--   means that while query results can be used as input parameters to
--   later queries, they cannot be used to decide to run completely
--   different queries based on other query results. Allowing this would
--   prevent the <a>Plan</a> structure from eliminating N+1 query loops.
--   
--   Note that during execution queries are never combined across tables to
--   form joins or subqueries. Queries are still executed in the same
--   sequence as specified in the plan, just on all the inputs at once
--   rather than in a loop. If you need to do a join with a plan, you can
--   always construction your own custom <a>Operation</a> and use
--   <a>planOperation</a> to incorporate into a plan.
--   
--   The <tt>param</tt> type variable indicates what type of value is
--   expected as input when the plan is executed.
--   
--   The <tt>result</tt> type for a plan indicates what Haskell type is
--   produced when the plan is executed.
--   
--   The <tt>scope</tt> type is used internally by Orville to track the
--   plan is currently executed against a single input or multiple inputs.
--   This type parameter should never specified as a concrete type in user
--   code, but must be exposed as a variable to ensure that execute scope
--   is tracked correctly through usages of <a>bind</a>.
data Plan scope param result

-- | A <a>Planned</a> value is a wrapper around the results of previous run
--   queries when using the <a>bind</a> function. At the time that you are
--   writing a plan you do not know whether the <a>Plan</a> will be run
--   with a single input or multiple inputs. A <a>Planned</a> value may end
--   up being either an individual item or a list of items. Due to this,
--   your ability to interact with the value is limited to the use of
--   <a>fmap</a> to extract (or build) other values from the results.
--   <a>Planned</a> values can be used together with the <a>use</a>
--   function to make a <a>Plan</a> that produces the extracted value.
--   
--   Note that while <a>Planned</a> could provide an <a>Applicative</a>
--   instance as well, it does not to avoid confusion with
--   <a>Applicative</a> instance for <a>Plan</a> itself. If you need to
--   build a value from several <a>Planned</a> values using
--   <a>Applicative</a>, you should call <a>use</a> on each of the values
--   and use the <a>Applicative</a> instance for <a>Plan</a>.
data Planned scope param a

-- | <a>Execute</a> is a tag type used by as the <tt>scope</tt> variable
--   for <a>Plan</a> values when executing them via the <a>execute</a>
--   function.
data Execute

-- | <a>Explain</a> is an tag type used as the <tt>scope</tt> variable when
--   explaining a <a>Plan</a> via the <a>explain</a> function.
data Explain

-- | <a>askParam</a> allows the input parameter for the plan to be
--   retrieved as the result of the plan. Together with <a>bind</a> you can
--   use this to get access to the input parameter as a <a>Planned</a>
--   value.
askParam :: Plan scope param param

-- | <a>execute</a> accepts the input parameter (or parameters) expected by
--   a <a>Plan</a> and runs the plan to completion, either throwing an
--   <a>AssertionFailed</a> exception in the monad <tt>m</tt> or producing
--   the expected result.
--   
--   If you have a plan that takes one input and want to provide a list of
--   input, use <a>planMany</a> to adapt it to a multple-input plan before
--   calling <a>execute</a>.
execute :: MonadOrville conn m => Plan Execute param result -> param -> m result

-- | <a>explain</a> produces a textual description of the steps outlined by
--   a <a>Plan</a> -- in most cases example SQL queries. If you want to see
--   the explanation of how the plan will run with multiple input
--   parameters, you can use <a>planMany</a> to adapt it before calling
--   <a>explain</a>.
explain :: Plan Explain param result -> [String]

-- | <a>findMaybeOne</a> constructs a <a>Plan</a> that will find at most
--   one row from the given table where the plan's input value matches the
--   given database field.
findMaybeOne :: Ord fieldValue => TableDefinition readEntity writeEntity key -> FieldDefinition nullability fieldValue -> Plan scope fieldValue (Maybe readEntity)

-- | <a>findMaybeOneWhere</a> is similar to <a>findMaybeOne</a>, but allows
--   a <tt>WhereCondition</tt> to be specified to restrict which rows are
--   matched by the database query.
findMaybeOneWhere :: Ord fieldValue => TableDefinition readEntity writeEntity key -> FieldDefinition nullability fieldValue -> WhereCondition -> Plan scope fieldValue (Maybe readEntity)

-- | <a>findOne</a> is an alias to <a>findOneShowVia</a> that uses the
--   <a>Show</a> instance of <tt>fieldValue</tt> when producing a failure
--   message in the result the entity cannot be found.
findOne :: (Show fieldValue, Ord fieldValue) => TableDefinition readEntity writeEntity key -> FieldDefinition nullability fieldValue -> Plan scope fieldValue readEntity

-- | <a>findOneShowVia</a> is similar to 'findMaybeOne, but it expects that
--   there will always be a row found matching the plan's input value. If
--   no row is found an <a>AssertionFailed</a> exception will be thrown.
--   This is a useful convenience when looking up foreign-key associations
--   that are expected to be enforced by the database itself.
findOneShowVia :: Ord fieldValue => (fieldValue -> String) -> TableDefinition readEntity writeEntity key -> FieldDefinition nullability fieldValue -> Plan scope fieldValue readEntity

-- | <a>findOneWhere</a> is an alias to <a>findOneWhereShowVia</a> that
--   uses the <a>Show</a> instance of <tt>fieldValue</tt> when producing a
--   failure message in the result the entity cannot be found.
findOneWhere :: (Show fieldValue, Ord fieldValue) => TableDefinition readEntity writeEntity key -> FieldDefinition nullability fieldValue -> WhereCondition -> Plan scope fieldValue readEntity

-- | <a>findOneWhereShowVia</a> is similar to <a>findOneShowVia</a>, but
--   allows a <tt>WhereCondition</tt> to be specified to restrict which
--   rows are matched by the database query.
findOneWhereShowVia :: Ord fieldValue => (fieldValue -> String) -> TableDefinition readEntity writeEntity key -> FieldDefinition nullability fieldValue -> WhereCondition -> Plan scope fieldValue readEntity

-- | <a>findAll</a> constructs a <a>Plan</a> that will find all the rows
--   from the given table there the plan's input value matches the given
--   database field.
findAll :: Ord fieldValue => TableDefinition readEntity writeEntity key -> FieldDefinition nullability fieldValue -> Plan scope fieldValue [readEntity]

-- | <a>findAllWhere</a> is similar to <a>findAll</a>, but allows a
--   <tt>WhereCondition</tt> to be specified to restrict which rows are
--   matched by the database query.
findAllWhere :: Ord fieldValue => TableDefinition readEntity writeEntity key -> FieldDefinition nullability fieldValue -> WhereCondition -> Plan scope fieldValue [readEntity]

-- | <a>bind</a> gives access to the results of a plan to use as input
--   values to future plans. The plan result is given the input parameter
--   to the provided function, which must produce the remaining <a>Plan</a>
--   to be executed. The value will be wrapped in the <a>Planned</a> type,
--   which may represent either a result or multiple results, depending on
--   whether one plan is currently be executed with one and multiple input
--   parameters. This ensures that the caller produces only a single
--   remaining <a>Plan</a> to be used for all inputs when there are
--   multiple to eliminate the need to possibly run different queries for
--   different inputs (which would an introduce N+1 query execution).
--   
--   The <a>Planned</a> value (or values) provided by <a>bind</a> have
--   actually been retrieved from the database, so the value can be used
--   multiple times when constructing the remaining <a>Plan</a> without
--   fear of causing the query to run multiple times.
--   
--   Also see <a>use</a> for how to lift a <a>Planned</a> value back into a
--   <a>Plan</a>.
bind :: Plan scope param a -> (Planned scope param a -> Plan scope param result) -> Plan scope param result

-- | <a>use</a> constructs a <a>Plan</a> that always produces the
--   <a>Planned</a> value as its result, regardless of the parameter given
--   as input to the plan.
use :: Planned scope param a -> Plan scope param a

-- | <a>using</a> uses a <a>Planned</a> value in the input to another
--   <a>Plan</a>. The resulting plan will ignore its input and use the
--   <a>Planned</a> value as the input to produce its result instead.
using :: Planned scope param a -> Plan scope a b -> Plan scope param b

-- | <a>chain</a> connects the output of one plan to the input of another
--   to form a larger plan that will execute the first followed by the
--   second.
chain :: Plan scope a b -> Plan scope b c -> Plan scope a c

-- | <a>apply</a> applies a function produced by a plan to the value
--   produced by another plan. This is usually used via the
--   <a>&lt;*&gt;</a> operator through the <a>Applicative</a> instance for
--   <a>Plan</a>.
apply :: Plan scope param (a -> b) -> Plan scope param a -> Plan scope param b

-- | <a>planMany</a> adapts a plan that takes a single input parameter to
--   work on multiple input parameters. When the new plan is executed each
--   query will execute in the same basic order, but with adjusted
--   conditions to find all the rows for all inputs at once rather than
--   running the planned queries once for each input.
planMany :: (forall manyScope. Plan manyScope param result) -> Plan scope [param] (Many param result)

-- | <a>planList</a> lifts a plan so both its param and result become
--   lists. This saves you from having to fmap in <a>elems</a> when all you
--   want back from a <a>Many</a> is the list of results inside it.
planList :: (forall scope. Plan scope param result) -> Plan listScope [param] [result]

-- | <a>focusParam</a> builds a plan from a function and an existing plan
--   taking the result of that function as input. This is especially useful
--   when there is some structure, and a plan that only needs a part of
--   that structure as input. The function argument can access part of the
--   structure for the plan argument to use, so the final returned plan can
--   take the entire structure as input.
focusParam :: (a -> b) -> Plan scope b result -> Plan scope a result

-- | <a>planEither</a> lets you construct a plan that branches by executing
--   a different plan for the <a>Left</a> and <a>Right</a> sides of an
--   <a>Either</a> value. When used with a single input parameter only one
--   of the two plans will be used, based on the input parameter. When used
--   on multiple input parameters, each of the two plans will be executed
--   only once with all the <a>Left</a> and <a>Right</a> values provided as
--   input parameters respectively.
planEither :: Plan scope leftParam leftResult -> Plan scope rightParam rightResult -> Plan scope (Either leftParam rightParam) (Either leftResult rightResult)

-- | <a>planMaybe</a> lifts a plan so both its param and result become
--   <a>Maybe</a>s. This is useful when modifying an existing plan to deal
--   with optionality. Writing just one plan can then easily produce both
--   the required and optional versions.
planMaybe :: Plan scope a b -> Plan scope (Maybe a) (Maybe b)

-- | <a>AssertionFailed</a> may be returned from the execute functions of
--   an <a>Operation</a> to indicate that some expected invariant has
--   failed. For example, following a foreign key that is enforced by the
--   database only to find that no record exists. When an <a>Operation</a>
--   returns an <a>AssertionFailed</a> value during plan execution the
--   error is thrown as an exception using the <a>MonadThrow</a> instance
--   for whatever monad the plan is executing in.
data AssertionFailed

-- | <a>assert</a> allows you to make an assertion about a plans result
--   that will throw an <a>AssertionFailed</a> failed exception during
--   execution if it proves to be false. The first parameter is the
--   assertion function, which should return either an error message to be
--   given in the exception or the value to be used as the plan's result.
assert :: (param -> a -> Either String b) -> Plan scope param a -> Plan scope param b

-- | <a>planSelect</a> allows any Orville <a>Select</a> query to be
--   incorporated into a plan. Note that the <a>Select</a> cannot depend on
--   the plan's input parameters in this case. If the plan is executed with
--   multiple inputs the same set of all the results will be used as the
--   results for each of the input parameters.
planSelect :: Select row -> Plan scope () [row]

-- | <a>planOperation</a> allows any primitive <a>Operation</a> to be used
--   as an atomic step in a plan. When the plan is executed, the
--   appropriate <a>Operation</a> functions will be used depending on the
--   execution context.
planOperation :: Operation param result -> Plan scope param result
instance GHC.Base.Functor (Database.Orville.PostgreSQL.Plan.Plan scope param)
instance GHC.Base.Applicative (Database.Orville.PostgreSQL.Plan.Plan scope param)
instance GHC.Base.Functor (Database.Orville.PostgreSQL.Plan.Planned scope param)


-- | This module exports the <a>bind</a> function as <a>&gt;&gt;=</a> so
--   that it can be used in conjuction with the <tt>QualifiedDo</tt>
--   language extension to write plans using do syntax like so:
--   
--   <pre>
--   module MyModule where
--   
--   import qualified Orville.PostgreSQL.Plan.Syntax as PlanSyntax
--   
--   data FooFamily =
--     FooFamily
--       { foo :: Foo
--       , children :: [FooChildren]
--       , pets :: [FooPets]
--       }
--   
--   findFooFamily = PlanSyntax.do $
--     fooHeader &lt;- Plan.findOne fooTable fooIdField
--     fooChildren &lt;- Plan.findAll fooChildTable fooIdField
--     fooPets &lt;- Plan.findAll fooPetTable fooIdField
--   
--     FooFamily
--       <a>$</a> Plan.use fooHeader
--       <a>*</a> Plan.use fooChildren
--       <a>*</a> Plan.use fooPets
--   </pre>
module Database.Orville.PostgreSQL.Plan.Syntax

-- | An operator alias of <a>bind</a> so that it can be used with
--   <tt>QualifiedDo</tt>.
(>>=) :: Plan scope param a -> (Planned scope param a -> Plan scope param result) -> Plan scope param result


-- | See <a>Database.Orville.PostgreSQL.Core</a> for information about
--   migrating to the new LibPQ-based Orville.
module Database.Orville.PostgreSQL

module Database.Orville.PostgreSQL.Trigger
insertTriggered :: (MonadThrow m, MonadOrville conn m, MonadTrigger trigger m, InsertTrigger trigger readEntity) => TableDefinition readEntity writeEntity key -> writeEntity -> m readEntity
class InsertTrigger trigger readEntity
insertTriggers :: InsertTrigger trigger readEntity => readEntity -> [trigger]
updateTriggered :: (MonadThrow m, MonadOrville conn m, MonadTrigger trigger m, UpdateTrigger trigger readEntity writeEntity) => TableDefinition readEntity writeEntity key -> readEntity -> writeEntity -> m ()
class UpdateTrigger trigger readEntity writeEntity
updateTriggers :: UpdateTrigger trigger readEntity writeEntity => readEntity -> writeEntity -> [trigger]
deleteTriggered :: (MonadThrow m, MonadOrville conn m, MonadTrigger trigger m, DeleteTrigger trigger readEntity) => TableDefinition readEntity writeEntity key -> readEntity -> m ()
class DeleteTrigger trigger readEntity
deleteTriggers :: DeleteTrigger trigger readEntity => readEntity -> [trigger]
class MonadTrigger trigger m | m -> trigger
runTriggers :: MonadTrigger trigger m => [trigger] -> m ()
data OrvilleTriggerT trigger conn m a
data RecordedTriggers trigger
committedTriggers :: RecordedTriggers trigger -> [trigger]
uncommittedTriggers :: RecordedTriggers trigger -> Maybe [trigger]
runOrvilleTriggerT :: MonadIO m => OrvilleTriggerT trigger conn m a -> Pool conn -> m (a, [trigger])
mapOrvilleTriggerT :: Monad n => (m a -> n b) -> OrvilleTriggerT trigger conn m a -> OrvilleTriggerT trigger conn n b
liftOrville :: Monad m => OrvilleT conn m a -> OrvilleTriggerT trigger conn m a
askTriggers :: MonadIO m => OrvilleTriggerT trigger conn m (RecordedTriggers trigger)
clearTriggers :: MonadIO m => OrvilleTriggerT trigger conn m ()


-- | <a>MonadUnliftIO</a> provides functions and instances for using
--   <tt>MonadOrville</tt> and <tt>OrvilleT</tt> for Monad transformer
--   stacks that are using <tt>MonadUnliftIO</tt>. The most common way to
--   do this is simply to add the following <tt>MonadOrvilleControl</tt>
--   instance:
--   
--   <pre>
--   instance MonadOrvilleControl MyMonad where
--     liftWithConnection = liftWithConnectionViaUnliftIO
--     liftFinally = liftFinallyViaUnliftIO
--   </pre>
--   
--   This module also provides a <tt>MonadUnliftIO</tt> instance for
--   <tt>OrvilleT</tt> and <tt>OrvilleTrigger</tt>. |
module Database.Orville.PostgreSQL.MonadUnliftIO

-- | liftWithConnectionViaUnliftIO can be use as the implementation of
--   <tt>liftWithConnection</tt> for <tt>MonadOrvilleControl</tt> when the
--   <a>Monad</a> implements <tt>MonadUnliftIO</tt>. |
liftWithConnectionViaUnliftIO :: MonadUnliftIO m => (forall a. (conn -> IO a) -> IO a) -> (conn -> m b) -> m b

-- | liftFinallyViaUnliftIO can be use as the implementation of
--   <tt>liftFinally</tt> for <tt>MonadOrvilleControl</tt> when the
--   <a>Monad</a> implements <tt>MonadUnliftIO</tt>. |
liftFinallyViaUnliftIO :: MonadUnliftIO m => (forall a b. IO a -> IO b -> IO a) -> m c -> m d -> m c
instance Control.Monad.IO.Unlift.MonadUnliftIO m => Control.Monad.IO.Unlift.MonadUnliftIO (Database.Orville.PostgreSQL.Internal.Monad.OrvilleT conn m)
instance Control.Monad.IO.Unlift.MonadUnliftIO m => Control.Monad.IO.Unlift.MonadUnliftIO (Database.Orville.PostgreSQL.Internal.Trigger.OrvilleTriggerT trigger conn m)


-- | <a>ResourceT</a> provides <a>ResourceT</a> instance of the Orville
--   typeclasses for situations where you might need it. In particular, if
--   you are using the conduit library, you may want to wrap
--   <a>ResourceT</a> around your normal monad stack, in which case you'll
--   need the <tt>MonadOrville</tt> instance provided here to use
--   <tt>selectConduit</tt>.
--   
--   These instances are not included in the default exports for Orville
--   because the required either a <a>MonadUnliftIO</a> or
--   <tt>MonadBaseControl</tt> instance of the monad underlying
--   <a>ResourceT</a>, depending on the version of <a>ResourceT</a> you are
--   using. For resource-1.1.10 and above you must provide
--   <a>MonadUnliftIO</a> instance. For versions prior to 1.1.10 you must
--   provide a <tt>MonadBaseControl</tt> instance.
--   
--   This is required by <tt>MonadOrville</tt> requires an instance to
--   <tt>MonadBaseControl</tt> to be defined. The instance provided here
--   can only use one lifting strategy, one we choose <a>MonadUnliftIO</a>
--   wherever possible (both by our own opinion and because later versions
--   of <a>ResourceT</a> have removed <tt>MonadBaseControl</tt> support).
--   <tt>MonadBaseControl</tt> is used for versions of <a>ResourceT</a>
--   before <a>ResourceT</a> supported <a>MonadUnliftIO</a>.
module Database.Orville.PostgreSQL.ResourceT
instance (GHC.Base.Monad m, Database.Orville.PostgreSQL.Internal.Monad.HasOrvilleContext conn m) => Database.Orville.PostgreSQL.Internal.Monad.HasOrvilleContext conn (Control.Monad.Trans.Resource.Internal.ResourceT m)
instance (Database.Orville.PostgreSQL.Internal.Monad.MonadOrvilleControl m, Control.Monad.IO.Unlift.MonadUnliftIO m) => Database.Orville.PostgreSQL.Internal.Monad.MonadOrvilleControl (Control.Monad.Trans.Resource.Internal.ResourceT m)
instance (Control.Monad.IO.Unlift.MonadUnliftIO m, Database.Orville.PostgreSQL.Internal.Monad.MonadOrville conn m) => Database.Orville.PostgreSQL.Internal.Monad.MonadOrville conn (Control.Monad.Trans.Resource.Internal.ResourceT m)


-- | <a>MonadBaseControl</a> provides functions and instances for using
--   <tt>MonadOrville</tt> and <tt>OrvilleT</tt> for situations where you
--   need to use <tt>MonadBaseControl</tt>. If you do not know if you need
--   <tt>MonadBaseControl</tt>, then you probably don't need to use this
--   module. If you are thinking about using <tt>MonadBaseControl</tt>
--   instead of <tt>MonadUnliftIO</tt>, we recommend reading Michael
--   Snoyman's excellent "A Tale of Two Brackets"
--   (https:/<i>www.fpcomplete.com</i>blog<i>2017</i>06/tale-of-two-brackets)
--   if you have not already done so.
--   
--   If you're still here after reading above, this module provides the
--   functions you need to implement <tt>MonadOrvilleControl</tt> for your
--   Monad stack using its <tt>MonadBaseControl</tt> instance. The most
--   common way to do this is simply to add the following
--   <tt>MonadOrvilleControl</tt> instance:
--   
--   <pre>
--   instance MonadOrvilleControl MyMonad where
--     liftWithConnection = liftWithConnectionViaBaseControl
--     liftFinally = liftFinallyViaBaseControl
--   </pre>
--   
--   This module also provides a <tt>MonadOrvilleControl</tt> for
--   <a>StateT</a> as well as <tt>MonadBaseControl</tt> and
--   <tt>MonadTransControl</tt> instances for <tt>OrvilleT</tt> and
--   <tt>OrvilleTriggerT</tt>.
module Database.Orville.PostgreSQL.MonadBaseControl

-- | liftWithConnectionViaBaseControl can be use as the implementation of
--   <tt>liftWithConnection</tt> for <tt>MonadOrvilleControl</tt> when the
--   <a>Monad</a> implements <tt>MonadBaseControl</tt>.
liftWithConnectionViaBaseControl :: MonadBaseControl IO m => (forall b. (conn -> IO b) -> IO b) -> (conn -> m a) -> m a

-- | liftFinallyViaBaseControl can be use as the implementation of
--   'liftFinally for <tt>MonadOrvilleControl</tt> when the <a>Monad</a>
--   implements <tt>MonadBaseControl</tt>.
liftFinallyViaBaseControl :: MonadBaseControl IO m => (forall c d. IO c -> IO d -> IO c) -> m a -> m b -> m a
instance Control.Monad.Trans.Control.MonadBaseControl GHC.Types.IO m => Database.Orville.PostgreSQL.Internal.Monad.MonadOrvilleControl (Control.Monad.Trans.State.Lazy.StateT a m)
instance Control.Monad.Trans.Control.MonadTransControl (Database.Orville.PostgreSQL.Internal.Monad.OrvilleT conn)
instance Control.Monad.Trans.Control.MonadBaseControl b m => Control.Monad.Trans.Control.MonadBaseControl b (Database.Orville.PostgreSQL.Internal.Monad.OrvilleT conn m)
instance Control.Monad.Trans.Control.MonadTransControl (Database.Orville.PostgreSQL.Internal.Trigger.OrvilleTriggerT trigger conn)
instance Control.Monad.Trans.Control.MonadBaseControl b m => Control.Monad.Trans.Control.MonadBaseControl b (Database.Orville.PostgreSQL.Internal.Trigger.OrvilleTriggerT trigger conn m)
